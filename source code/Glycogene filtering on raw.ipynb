{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2143c82d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as plt\n",
    "import torch as pt\n",
    "import csv\n",
    "import pickle #to save notebook at sessions\n",
    "\n",
    "#set path for pickles to be saved in\n",
    "pickle_path = '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/python pickles/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068cec0",
   "metadata": {},
   "source": [
    "# What is going on (on raw counts)\n",
    "1. Import glycogene csv of human glycogenes converted to mice homologs (because our data is from mice tumor models. Human glycogenes are from glyco.me (Glycopacity). \n",
    "2. Load barcodes, features, and matrix of LN and TILs and convert to dataframe\n",
    "3. Import transformed identity csv with info on which cells are associated with which cell type\n",
    "4. Filter cells from original dataframe to produce smaller dataframe of just TILs in LN/TIL population from transformed identity csv\n",
    "5. Filter genes from filtered dataframe (from 4) to only include glycogenes from (1)\n",
    "6. Convert filtered dataframe back into a sparse matrix for export into .mtx file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac3d0e",
   "metadata": {},
   "source": [
    "## 1. Import human to mouse glycogene csv.\n",
    "Converted human glycogenes to their mouse homologs via https://www.informatics.jax.org/batch/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a61d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glyco_fp = '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/human to mouse glycogene converted.csv'\n",
    "glycogene_df = pd.read_csv(glyco_fp)\n",
    "#make mouse glycogene list\n",
    "m_glyco = glycogene_df[['Mouse']]\n",
    "mouse_glycogenes = list(m_glyco.dropna(axis=0)['Mouse']) #removed 3 genes that didn't have mice homologs\n",
    "\n",
    "#export just the mouse glycogenes as csv\n",
    "m_glyco.to_csv('Mouse glycogenes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99d246c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mouse_glycogenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90fdba",
   "metadata": {},
   "source": [
    "## 2. Load barcodes, features, and matrix of LN and TILs and convert to dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd05562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TAKES LONG TIME TO RUN!! ## \n",
    "# Load the LN SUGAR-seq matrix from file\n",
    "sparse_LN = sp.io.mmread(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/matrix.mtx')\n",
    "# Convert to CSR format\n",
    "sparse_LN = sp.sparse.csr_matrix(sparse_LN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c2b8b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_72324/477600803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## TAKES LONG TIME TO RUN!! ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load the TIL SUGAR-seq matrix from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m sparse_TIL = sp.io.mmread(\n\u001b[0m\u001b[1;32m      4\u001b[0m     '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx')\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert to CSR format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/io/_mmio.py\u001b[0m in \u001b[0;36mmmread\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMMFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/io/_mmio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/io/_mmio.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(filespec, mode)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilespec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilespec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# open for writing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx'"
     ]
    }
   ],
   "source": [
    "## TAKES LONG TIME TO RUN!! ## \n",
    "# Load the TIL SUGAR-seq matrix from file\n",
    "sparse_TIL = sp.io.mmread(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx')\n",
    "# Convert to CSR format\n",
    "sparse_TIL = sp.sparse.csr_matrix(sparse_TIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension check of sparse matrix\n",
    "print('LN matrix dimesions are', np.shape(sparse_LN)) #31059 = rows , 21343=columns\n",
    "print('TIL matrix dimesions are', np.shape(sparse_TIL))\n",
    "\n",
    "# convert sparse matrices to array to put into dataframe\n",
    "LN_matrix = sparse_LN.toarray()\n",
    "TIL_matrix = sparse_TIL.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d82de",
   "metadata": {},
   "source": [
    "### Set up data frame for TIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807dfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TIL data ##  \n",
    "# barcodes = row names\n",
    "barcodes = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/barcodes copy.tsv', \n",
    "    header=None)\n",
    "barcodes = barcodes.rename(columns={0: 'barcode'})\n",
    "TIL_barcodes = list(barcodes['barcode']) # of columns =  21343\n",
    "\n",
    "# features = column names\n",
    "feats = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/features.tsv', \n",
    "    header = None)\n",
    "with open('/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/features.tsv', \n",
    "          'r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    feat_ls = []\n",
    "    for row in reader:\n",
    "        feat_ls.append(row)\n",
    "TIL_features = [i[1] for i in feat_ls] # of rows = 31059\n",
    "\n",
    "# Convert the dense matrix to a pandas DataFrame\n",
    "TIL_df = pd.DataFrame(data=TIL_matrix, index=TIL_features, columns=TIL_barcodes)\n",
    "\n",
    "# Remove rows for HTO1, HTO2, PD1, and TIM3 (ADT and HTO assays)\n",
    "TIL_df_new = TIL_df.drop(['HTO1', 'HTO2','PD1', 'TIM3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f68f99",
   "metadata": {},
   "source": [
    "### set up dataframe for LN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a23ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LN data ## \n",
    "# barcodes = row names\n",
    "barcodes = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/barcodes copy.tsv', \n",
    "    header=None)\n",
    "barcodes = barcodes.rename(columns={0: 'barcode'})\n",
    "LN_barcodes = list(barcodes['barcode']) # of columns =  21343\n",
    "\n",
    "# features = column names\n",
    "feats = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/features.tsv', header = None)\n",
    "with open('/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/features.tsv', \n",
    "          'r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    feat_ls = []\n",
    "    for row in reader:\n",
    "        feat_ls.append(row)\n",
    "LN_features = [i[1] for i in feat_ls] # of rows = 31059\n",
    "\n",
    "# Convert the dense matrix to a pandas DataFrame with columns as each barcode and rows as each gene\n",
    "LN_df = pd.DataFrame(data=LN_matrix, index=LN_features, columns=LN_barcodes)\n",
    "\n",
    "# Remove rows for HTO1, HTO2, PD1, and TIM3 (ADT and HTO assays)\n",
    "LN_df_new = LN_df.drop(['hashtag1', 'hashtag2','hashtag3', 'PD1_hash', 'TIM3_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL df set up.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_df_new, f)\n",
    "    \n",
    "with open(pickle_path + 'LN df set up.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_df_new, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f52bf",
   "metadata": {},
   "source": [
    "## 3. Add cell type info from csv exported from ProjecTIL cell type annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa85488",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL df set up.pkl', 'rb') as f:\n",
    "    TIL_df_new = pickle.load(f)\n",
    "\n",
    "with open(pickle_path + 'LN df set up.pkl', 'rb') as f:\n",
    "    LN_df_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cdbfeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_TIL='/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/TIL output/ProjecTIL analysis/TIL_transformed_identity.csv'\n",
    "path_LN='/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/LN output/ProjecTIL analysis/LN_transformed_identity.csv'\n",
    "\n",
    "# import ProjecTIL analysis output to add cell type annotation to raw glycogene data frame \n",
    "TIL_transformed_ident = pd.read_csv(path_TIL)\n",
    "LN_transformed_ident = pd.read_csv(path_LN)\n",
    "\n",
    "#rename column of ProjecTIL df for easy identification of barcodes\n",
    "TIL_transformed_ident = TIL_transformed_ident.rename(columns={'Unnamed: 0':'Barcodes'}) \n",
    "LN_transformed_ident = LN_transformed_ident.rename(columns={'Unnamed: 0':'Barcodes'}) \n",
    "\n",
    "#Transpose matrix to match final TIL/LN matrix format\n",
    "TIL_transformed_ident = TIL_transformed_ident.transpose()\n",
    "LN_transformed_ident = LN_transformed_ident.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1dd9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUn only once, else it keeps replacing index with top row. if you run too much, rerun previous cell first!! \n",
    "'''\n",
    "make the column names the barcodes, which is how the glycogene \n",
    "dataframe (the one we want to combine this one with) is formatted as, to concatenate\n",
    "'''\n",
    "TIL_transformed_ident.set_axis(TIL_transformed_ident.iloc[0], axis=1, inplace=True)\n",
    "TIL_transformed_ident = TIL_transformed_ident[1:] \n",
    "\n",
    "LN_transformed_ident.set_axis(LN_transformed_ident.iloc[0], axis=1, inplace=True)\n",
    "LN_transformed_ident = LN_transformed_ident[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as binarized pickle file \n",
    "with open(pickle_path + 'TIL_transformed_ident.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_transformed_ident, f)\n",
    "    \n",
    "with open(pickle_path + 'LN_transformed_ident.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_transformed_ident, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5e874",
   "metadata": {},
   "source": [
    "### Remove non-TILs from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5049fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe dimensions are  (31054, 19912) and the filtered dataframe dimensions are (31054, 19645)\n",
      "Original dataframe dimensions are  (31054, 21343) and the filtered dataframe dimensions are (31054, 21296)\n"
     ]
    }
   ],
   "source": [
    "# # filter original matrix by barcodes of cells identified as TILs via ProjecTILs #\n",
    "\n",
    "# extract list of barcodes that have a T-cell annotation\n",
    "TIL_barcodes = list(TIL_transformed_ident.columns)\n",
    "LN_barcodes = list(LN_transformed_ident.columns)\n",
    "\n",
    "\n",
    "filtered_TIL_df = TIL_df_new[TIL_barcodes]\n",
    "filtered_LN_df = LN_df_new[LN_barcodes]\n",
    "\n",
    "print('Original dataframe dimensions are ', TIL_df_new.shape, \n",
    "      'and the filtered dataframe dimensions are', filtered_TIL_df.shape)\n",
    "print('Original dataframe dimensions are ', LN_df_new.shape, \n",
    "      'and the filtered dataframe dimensions are', filtered_LN_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as binarized pickle file \n",
    "with open(pickle_path + 'filtered_TIL_df.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_TIL_df, f)\n",
    "    \n",
    "with open(pickle_path + 'filtered_LN_df.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_LN_df, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97ec8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##TAKES LONG TIME TO RUN##\n",
    "'''\n",
    "Add cell type information via concatenation\n",
    "Note: the L-Pha information from this csv is normalized, and since we're using raw data we'll use the raw biotin info\n",
    "'''\n",
    "TIL_type = TIL_transformed_ident.loc[['Type']]\n",
    "LN_type = LN_transformed_ident.loc[['Type']]\n",
    "\n",
    "#makes new dataframe that adds T-cell type annotations to raw gene expression dataframe \n",
    "TIL_type_df = pd.concat([filtered_TIL_df, TIL_type])\n",
    "LN_type_df = pd.concat([filtered_LN_df, LN_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd39b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL_type_df.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_type_df, f)\n",
    "    \n",
    "with open(pickle_path + 'LN_type_df.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_type_df, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0e141",
   "metadata": {},
   "source": [
    "## 4. Filter matrix to only include glycogenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4104a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL_type_df.pkl', 'rb') as f:\n",
    "    TIL_type_df = pickle.load(f)\n",
    "\n",
    "with open(pickle_path + 'LN_type_df.pkl', 'rb') as f:\n",
    "    LN_type_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96922652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of glycogenes looked for: 264\n",
      "Number of glycogenes found in TILs: 261\n",
      "Number of glycogenes found in LNs: 261\n"
     ]
    }
   ],
   "source": [
    "# filter the original matrix by the mouse glycogenes but keep biotin and type info\n",
    "print('Total number of glycogenes looked for:', len(mouse_glycogenes))\n",
    "\n",
    "#Look for glycogenes within TIL_type_df\n",
    "TILglycogenes_found = [i for i in mouse_glycogenes if i in TIL_type_df.index]\n",
    "TILglycogenes_notfound = [i for i in mouse_glycogenes if i not in TIL_type_df.index]\n",
    "\n",
    "glycoTIL_df = TIL_type_df.loc[TILglycogenes_found + ['Biotin', 'Type']] #filter by glycogenes while keeping type&biotin\n",
    "print('Number of glycogenes found in TILs:', len(glycoTIL_df)-2) #-2 accounts for extra type and biotin rows\n",
    "\n",
    "\n",
    "#Look for glycogenes within LN_type_df\n",
    "LNglycogenes_found = [i for i in mouse_glycogenes if i in LN_type_df.index]\n",
    "LNglycogenes_notfound = [i for i in mouse_glycogenes if i not in LN_type_df.index]\n",
    "\n",
    "glycoLN_df = LN_type_df.loc[LNglycogenes_found + ['Biotin_hash', 'Type']] #filter by glycogenes while keeping type&biotin\n",
    "print('Number of glycogenes found in LNs:', len(glycoLN_df) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6782e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'glycoTIL_df.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoTIL_df, f)\n",
    "    \n",
    "with open(pickle_path + 'glycoLN_df.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoLN_df, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27290cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Couldn't find all the genes from glycogene list in dataset, see if we're missing any homologs etc...\n",
    "THe same glycogenes that weren't found in TILs were also not found in LN\n",
    "'''\n",
    "TILnot = [i for i in mouse_glycogenes not in glycoTIL_df.index]\n",
    "TILnot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2543afc",
   "metadata": {},
   "source": [
    "## 5. Sort dataframe by biotin values and assign 1/0 to each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08db08ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load updated df from pickle\n",
    "pickle_in = open(pickle_path + \"glycoTIL_df.pkl\",\"rb\")\n",
    "glycoTIL_df = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(pickle_path + \"glycoLN_df.pkl\",\"rb\")\n",
    "glycoLN_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f6c4332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose matrix for easy sorting\n",
    "glycoTIL_df = glycoTIL_df.transpose()\n",
    "glycoLN_df = glycoLN_df.transpose()\n",
    "\n",
    "#Sort the cells based on their biotin values\n",
    "final_TIL_df = glycoTIL_df.sort_values(by='Biotin', ascending = False)\n",
    "#final_LN_df = glycoLN_df.sort_values(by='Biotin_hash', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af594ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# swap locations of type and biotin columns for easy lectin categorization\n",
    "'''\n",
    "### for TIL_SCT_final: ###\n",
    "TIL_fin = final_TIL_df.iloc[:, :-2]\n",
    "TIL_final = TIL_fin.copy()\n",
    "TIL_final.loc[:, 'Type']=list(final_TIL_df['Type'])\n",
    "TIL_final.loc[:, 'Biotin norm.']=list(final_TIL_df['Biotin'])\n",
    "final_TIL_df = TIL_final\n",
    "\n",
    "### for TIL_SCT_final: ###\n",
    "LN_fin = final_LN_df.iloc[:, :-2]\n",
    "LN_final = LN_fin.copy()\n",
    "LN_final.loc[:, 'Type']=list(final_LN_df['Type'])\n",
    "LN_final.loc[:, 'Biotin norm.']=list(final_LN_df['Biotin_hash'])\n",
    "final_LN_df = LN_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f52b96c",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_27260/3895279790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ## load updated df from pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpickle_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_path\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"final_TIL_df.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfinal_TIL_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# pickle_in = open(pickle_path +\"final_LN_df.pkl\",\"rb\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# # save pickle \n",
    "# with open(pickle_path + 'final_TIL_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(final_TIL_df, f)\n",
    "    \n",
    "# with open(pickle_path + 'final_LN_df.pkl', 'wb') as f:\n",
    "#     pickle.dump(final_LN_df, f)\n",
    "\n",
    "# f.close()\n",
    "\n",
    " \n",
    "# ## load updated df from pickle\n",
    "pickle_in = open(pickle_path +\"final_TIL_df.pkl\",\"rb\")\n",
    "final_TIL_df = pickle.load(pickle_in)\n",
    "\n",
    "# pickle_in = open(pickle_path +\"final_LN_df.pkl\",\"rb\")\n",
    "# final_LN_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce9907d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ahsa1</th>\n",
       "      <th>Api5</th>\n",
       "      <th>Atp6v1e1</th>\n",
       "      <th>Bcap31</th>\n",
       "      <th>Cops6</th>\n",
       "      <th>Csnk2b</th>\n",
       "      <th>Eif3i</th>\n",
       "      <th>Eif4g2</th>\n",
       "      <th>Gdi2</th>\n",
       "      <th>Hnrnpf</th>\n",
       "      <th>...</th>\n",
       "      <th>Galntl6</th>\n",
       "      <th>Galntl5</th>\n",
       "      <th>Galnt13</th>\n",
       "      <th>Galnt15</th>\n",
       "      <th>Galnt14</th>\n",
       "      <th>Dse</th>\n",
       "      <th>Dsel</th>\n",
       "      <th>Glce</th>\n",
       "      <th>Type</th>\n",
       "      <th>Biotin norm.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TACAGTGGTTCAACCA-1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>37384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACATACGAGTGCCATT-1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "      <td>33249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGTCCCATCGGCTTGG-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Th1</td>\n",
       "      <td>32029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTGTCCAGGATGGTC-1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CD8_EarlyActiv</td>\n",
       "      <td>31700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAACATCTCTGCTGTC-1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Treg</td>\n",
       "      <td>31402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGTCAGGGTTTGACAC-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGGTCTCGAACTGT-1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCTGCTTCACCAACCG-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGGTTCCGTTGATTCG-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTGCGGACACGAAGCA-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19645 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Ahsa1 Api5 Atp6v1e1 Bcap31 Cops6 Csnk2b Eif3i Eif4g2 Gdi2  \\\n",
       "TACAGTGGTTCAACCA-1     0    1        1      1     0      0     1      0    0   \n",
       "ACATACGAGTGCCATT-1     0    2        0      0     0      4     2      0    4   \n",
       "TGTCCCATCGGCTTGG-1     0    0        0      1     0      0     1      3    1   \n",
       "ACTGTCCAGGATGGTC-1     0    1        0      1     0      0     0      0    0   \n",
       "GAACATCTCTGCTGTC-1     3    4        2      7     3     14    10      8   10   \n",
       "...                  ...  ...      ...    ...   ...    ...   ...    ...  ...   \n",
       "CGTCAGGGTTTGACAC-1     0    0        0      0     0      0     0      0    0   \n",
       "ACGGGTCTCGAACTGT-1     0    1        1      1     2      0     0      0    2   \n",
       "GCTGCTTCACCAACCG-1     0    0        0      0     0      1     0      0    0   \n",
       "TGGTTCCGTTGATTCG-1     0    0        0      0     0      0     0      0    1   \n",
       "CTGCGGACACGAAGCA-1     0    0        0      0     0      0     0      0    0   \n",
       "\n",
       "                   Hnrnpf  ... Galntl6 Galntl5 Galnt13 Galnt15 Galnt14 Dse  \\\n",
       "TACAGTGGTTCAACCA-1      2  ...       0       0       0       0       0   0   \n",
       "ACATACGAGTGCCATT-1      4  ...       0       0       0       0       0   0   \n",
       "TGTCCCATCGGCTTGG-1      2  ...       0       0       0       0       0   0   \n",
       "ACTGTCCAGGATGGTC-1      1  ...       0       0       0       0       0   0   \n",
       "GAACATCTCTGCTGTC-1     23  ...       0       0       0       0       0   0   \n",
       "...                   ...  ...     ...     ...     ...     ...     ...  ..   \n",
       "CGTCAGGGTTTGACAC-1      1  ...       0       0       0       0       0   0   \n",
       "ACGGGTCTCGAACTGT-1      4  ...       0       0       0       0       0   0   \n",
       "GCTGCTTCACCAACCG-1      1  ...       0       0       0       0       0   0   \n",
       "TGGTTCCGTTGATTCG-1      3  ...       0       0       0       0       0   0   \n",
       "CTGCGGACACGAAGCA-1      1  ...       0       0       0       0       0   0   \n",
       "\n",
       "                   Dsel Glce                Type Biotin norm.  \n",
       "TACAGTGGTTCAACCA-1    0    0       CD8_NaiveLike        37384  \n",
       "ACATACGAGTGCCATT-1    0    0  CD8_EffectorMemory        33249  \n",
       "TGTCCCATCGGCTTGG-1    0    0                 Th1        32029  \n",
       "ACTGTCCAGGATGGTC-1    0    0      CD8_EarlyActiv        31700  \n",
       "GAACATCTCTGCTGTC-1    0    1                Treg        31402  \n",
       "...                 ...  ...                 ...          ...  \n",
       "CGTCAGGGTTTGACAC-1    0    0       CD8_NaiveLike           15  \n",
       "ACGGGTCTCGAACTGT-1    0    0  CD8_EffectorMemory           13  \n",
       "GCTGCTTCACCAACCG-1    0    0       CD8_NaiveLike           11  \n",
       "TGGTTCCGTTGATTCG-1    0    0       CD8_NaiveLike           11  \n",
       "CTGCGGACACGAAGCA-1    0    0       CD8_NaiveLike            4  \n",
       "\n",
       "[19645 rows x 263 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_TIL_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3f075cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_27260/2844898492.py:24: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.iloc[:,ref_col_loc], [quantile_high, quantile_low],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off for PHA-L high: 738; Cut-off for PHA-L low: 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_27260/2844898492.py:24: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.iloc[:,ref_col_loc], [quantile_high, quantile_low],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off for PHA-L high: 276; Cut-off for PHA-L low: 127\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now want to add Glycosylation (PHA-L) column that assigns:\n",
    "Yes (1) to top 25%, \n",
    "No (0) to bottom 25%\n",
    "\n",
    "categorize_lectin inputs:\n",
    "- data_all: a dataframe that has\n",
    "    - genes in the columns headers\n",
    "    - barcodes as row indices\n",
    "    - a column with biotin values to use as cutoffs for top 25% and bottom 25%\n",
    "- quantile_high: upper quantile threshold (75% to represent top 25% of data below which 75% of the data falls)\n",
    "- quantile_low: lower quantile threshold (25% to represent bottom 25% of data below which 25% of data falls)\n",
    "- ref_col_loc: index of column in data_all that is used for categorization cutoffs\n",
    "\n",
    "outputs:\n",
    "- cutoff values for high and low biotin\n",
    "- list of 3 arrays representing indices of rows that meet the high biotin cutoff, \n",
    "low biotin cutoff, and combined high and low cutoff\n",
    "- number of rows that meet the high category cutoff and the low category cutoff.\n",
    "'''\n",
    "\n",
    "# Function: determine PHA-L read cut-offs for binary classification FROM BOJAR LAB\n",
    "def categorize_lectin(data_all, quantile_high, quantile_low, ref_col_loc):\n",
    "    cutoff = np.quantile(data_all.iloc[:,ref_col_loc], [quantile_high, quantile_low], \n",
    "                         interpolation=\"nearest\").tolist()\n",
    "    print(f\"Cut-off for PHA-L high: {cutoff[0]}; Cut-off for PHA-L low: {cutoff[1]}\")\n",
    "    \n",
    "    high_indices = np.array(data_all.iloc[:,ref_col_loc]>=cutoff[0])\n",
    "    low_indices = np.array(data_all.iloc[:,ref_col_loc]<cutoff[1])\n",
    "    high_low_indices = np.logical_or(high_indices, low_indices)\n",
    "\n",
    "    high_count = high_indices.sum()\n",
    "    low_count = low_indices.sum()\n",
    "    \n",
    "    return cutoff, [high_indices, low_indices, high_low_indices], [high_count, low_count]\n",
    "\n",
    "\n",
    "# Parameters for categorize lectin function\n",
    "quantile_high, quantile_low = 0.75, 0.25\n",
    "ref_col_index = -1 #last column of dataframes contain biotin info\n",
    "\n",
    "###for TILs###\n",
    "cutoff, indices, count = categorize_lectin(final_TIL_df, quantile_high, quantile_low, -1)\n",
    "\n",
    "glycosorted_TIL = final_TIL_df.copy()\n",
    "glycosorted_TIL.loc[indices[0], \"PHA-L\"] = 1 #add 1 to columns in the first list of index\n",
    "glycosorted_TIL.loc[indices[1], \"PHA-L\"] = 0\n",
    "glycosorted_TIL = glycosorted_TIL.loc[indices[2], :] #cuts out the middle 50% of the dataframe without PHA-L 1 or 0 \n",
    "\n",
    "###for LNs###\n",
    "cutoff, indices, count = categorize_lectin(final_LN_df, quantile_high, quantile_low, -1)\n",
    "glycosorted_LN = final_LN_df.copy()\n",
    "glycosorted_LN.loc[indices[0], \"PHA-L\"] = 1\n",
    "glycosorted_LN.loc[indices[1], \"PHA-L\"] = 0\n",
    "glycosorted_LN = glycosorted_LN.loc[indices[2], :] #cuts out the middle 50% of the dataframe without PHA-L 1 or 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "753bf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle \n",
    "with open(pickle_path + 'glycosorted_TIL.pkl', 'wb') as f:\n",
    "    pickle.dump(glycosorted_TIL, f)\n",
    "    \n",
    "with open(pickle_path + 'glycosorted_LN.pkl', 'wb') as f:\n",
    "    pickle.dump(glycosorted_LN, f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# # open via: \n",
    "# #load updated df from pickle\n",
    "# pickle_in = open(pickle_path +\"glycosorted_TIL.pkl\",\"rb\")\n",
    "# glycosorted_TIL = pickle.load(pickle_in)\n",
    "\n",
    "# pickle_in = open(pickle_path +\"glycosorted_LN.pkl\",\"rb\")\n",
    "# glycosorted_LN = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e82008",
   "metadata": {},
   "source": [
    "### Make a concatenated dataframe that combines LN and TIL t-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e2d7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run once!!\n",
    "glycoTIL = glycosorted_TIL.copy()\n",
    "glycoLN = glycosorted_LN.copy()\n",
    "\n",
    "#Add info about where t-cells are from (LN or TIL) just in case as column\n",
    "glycoTIL['Location'] = ['TIL' for i in range(len(glycoTIL))]\n",
    "glycoLN['Location'] = ['LN' for i in range(len(glycoLN))]\n",
    "\n",
    "#add location info to barcode identifier\n",
    "glycoTIL.index = [f\"{x}_TIL\" for x in glycoTIL.index]\n",
    "glycoLN.index = [f\"{x}_LN\" for x in glycoLN.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "30f97689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dimensions of TIL: (9824, 265)\n",
      "Initial dimensions of LN: (10595, 265)\n",
      "Combined dimensions: (20419, 265)\n"
     ]
    }
   ],
   "source": [
    "combo_raw = pd.concat([glycoTIL, glycoLN])\n",
    "print('Initial dimensions of TIL:', glycoTIL.shape)\n",
    "print('Initial dimensions of LN:', glycoLN.shape)\n",
    "print('Combined dimensions:', combo_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649e0818",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combo_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_27260/2675684960.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombo_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combo_raw' is not defined"
     ]
    }
   ],
   "source": [
    "combo_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9cd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save pickle \n",
    "# with open(pickle_path + 'combo_raw.pkl', 'wb') as f:\n",
    "#     pickle.dump(combo_raw, f)\n",
    "\n",
    "\n",
    "# f.close()\n",
    "\n",
    "# open via: \n",
    "#load updated df from pickle\n",
    "pickle_in = open(pickle_path +\"combo_raw.pkl\",\"rb\")\n",
    "combo_raw = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae460e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ahsa1</th>\n",
       "      <th>Api5</th>\n",
       "      <th>Atp6v1e1</th>\n",
       "      <th>Bcap31</th>\n",
       "      <th>Cops6</th>\n",
       "      <th>Csnk2b</th>\n",
       "      <th>Eif3i</th>\n",
       "      <th>Eif4g2</th>\n",
       "      <th>Gdi2</th>\n",
       "      <th>Hnrnpf</th>\n",
       "      <th>...</th>\n",
       "      <th>Galnt13</th>\n",
       "      <th>Galnt15</th>\n",
       "      <th>Galnt14</th>\n",
       "      <th>Dse</th>\n",
       "      <th>Dsel</th>\n",
       "      <th>Glce</th>\n",
       "      <th>Type</th>\n",
       "      <th>Biotin norm.</th>\n",
       "      <th>PHA-L</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AATCCAGCATATGCTG-1_TIL</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>13596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCCTCTATCTGGTTCC-1_TIL</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>4131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GACGTTACACGCCAGT-1_TIL</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>2879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGACAGACAGCTGTAT-1_TIL</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>1781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGACTTTTCACATAGC-1_TIL</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>1234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATTGGACGTAAACACA-1_LN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGGACGTAGTGGAGTC-1_LN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTACATTCATTTCAGG-1_LN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGCGTCCAGTCAGCC-1_LN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGACTAGCACCTTGTC-1_LN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ahsa1 Api5 Atp6v1e1 Bcap31 Cops6 Csnk2b Eif3i Eif4g2  \\\n",
       "AATCCAGCATATGCTG-1_TIL     2    0        0      0     0      2     3      1   \n",
       "GCCTCTATCTGGTTCC-1_TIL     2    1        0     12     0      1     2      7   \n",
       "GACGTTACACGCCAGT-1_TIL     4    2        1     12     9      6    16      8   \n",
       "GGACAGACAGCTGTAT-1_TIL     0    0        0     12     0      0     0      1   \n",
       "TGACTTTTCACATAGC-1_TIL     8    3        5      7     3      3     2     23   \n",
       "...                      ...  ...      ...    ...   ...    ...   ...    ...   \n",
       "ATTGGACGTAAACACA-1_LN      0    0        0      0     0      0     1      1   \n",
       "CGGACGTAGTGGAGTC-1_LN      1    1        0      1     2      2     2      4   \n",
       "CTACATTCATTTCAGG-1_LN      0    1        0      0     2      0     0      4   \n",
       "TTGCGTCCAGTCAGCC-1_LN      0    1        0      0     0      1     2      1   \n",
       "TGACTAGCACCTTGTC-1_LN      0    1        0      0     0      0     0      1   \n",
       "\n",
       "                       Gdi2 Hnrnpf  ... Galnt13 Galnt15 Galnt14 Dse Dsel Glce  \\\n",
       "AATCCAGCATATGCTG-1_TIL    2      5  ...       0       0       0   0    0    0   \n",
       "GCCTCTATCTGGTTCC-1_TIL    1      8  ...       0       0       0   2    0    0   \n",
       "GACGTTACACGCCAGT-1_TIL    3      3  ...       0       0       0   1    0    0   \n",
       "GGACAGACAGCTGTAT-1_TIL    1      4  ...       0       0       0   1    0    0   \n",
       "TGACTTTTCACATAGC-1_TIL    5     27  ...       0       0       0   1    1    1   \n",
       "...                     ...    ...  ...     ...     ...     ...  ..  ...  ...   \n",
       "ATTGGACGTAAACACA-1_LN     1      1  ...       0       0       0   0    0    0   \n",
       "CGGACGTAGTGGAGTC-1_LN     3      2  ...       0       0       0   0    0    0   \n",
       "CTACATTCATTTCAGG-1_LN     1      4  ...       0       0       0   0    0    0   \n",
       "TTGCGTCCAGTCAGCC-1_LN     1      5  ...       0       0       0   0    0    0   \n",
       "TGACTAGCACCTTGTC-1_LN     0      1  ...       0       0       0   0    0    0   \n",
       "\n",
       "                       Type Biotin norm. PHA-L Location  \n",
       "AATCCAGCATATGCTG-1_TIL  Tfh        13596   1.0      TIL  \n",
       "GCCTCTATCTGGTTCC-1_TIL  Tfh         4131   1.0      TIL  \n",
       "GACGTTACACGCCAGT-1_TIL  Tfh         2879   1.0      TIL  \n",
       "GGACAGACAGCTGTAT-1_TIL  Tfh         1781   1.0      TIL  \n",
       "TGACTTTTCACATAGC-1_TIL  Tfh         1234   1.0      TIL  \n",
       "...                     ...          ...   ...      ...  \n",
       "ATTGGACGTAAACACA-1_LN   Tfh          119   0.0       LN  \n",
       "CGGACGTAGTGGAGTC-1_LN   Tfh          112   0.0       LN  \n",
       "CTACATTCATTTCAGG-1_LN   Tfh          102   0.0       LN  \n",
       "TTGCGTCCAGTCAGCC-1_LN   Tfh           76   0.0       LN  \n",
       "TGACTAGCACCTTGTC-1_LN   Tfh           71   0.0       LN  \n",
       "\n",
       "[109 rows x 265 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_raw[combo_raw['Type'] == 'Tfh']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59abf2c",
   "metadata": {},
   "source": [
    "### SPlit by subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ae1e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now want to split up glycosorted dataframe into sub-dataframes for\n",
    "each of the different T-cell subtypes. TO do this, this code block takes in the glycosorted\n",
    "dataframe data as the input and spits out a dictionaryt containing:\n",
    "- t-cell type as key \n",
    "- matrix containing raw expression data for dataframe as values\n",
    "\n",
    "'''\n",
    "# Get list of T-cell subtypes for which to make a dataframe for TILs\n",
    "tcell_subtypes = glycosorted_TIL['Type'].unique()\n",
    "\n",
    "#make dataframe names for later access\n",
    "df_names = [i+'_df' for i in list(tcell_subtypes)]\n",
    "\n",
    "# Make copy of original df just in case\n",
    "split_df = glycosorted_TIL.copy()\n",
    "\n",
    "TILtcell_dfs = {}\n",
    "\n",
    "# Make separate dataframe containing data for each t-cell subtype\n",
    "for cell_type, name in zip(tcell_subtypes, df_names):\n",
    "    TILtcell_dfs[name] = split_df[split_df['Type'] == cell_type]\n",
    "    \n",
    "###----------------------------------------------------------------------\n",
    "# Get list of T-cell subtypes for which to make a dataframe for LNs\n",
    "tcell_subtypes = glycosorted_LN['Type'].unique()\n",
    "\n",
    "#make dataframe names for later access\n",
    "df_names = [i+'_df' for i in list(tcell_subtypes)]\n",
    "\n",
    "\n",
    "# Make copy of original df just in case\n",
    "split_df = glycosorted_LN.copy()\n",
    "\n",
    "LNtcell_dfs = {}\n",
    "# Make separate dataframe containing data for each t-cell subtype\n",
    "for cell_type, name in zip(tcell_subtypes, df_names):\n",
    "    LNtcell_dfs[name] = split_df[split_df['Type'] == cell_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cb3e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle \n",
    "with open(pickle_path + 'TILtcell_dfs.pkl', 'wb') as f:\n",
    "    pickle.dump(TILtcell_dfs, f)\n",
    "    \n",
    "with open(pickle_path + 'LNtcell_dfs.pkl', 'wb') as f:\n",
    "    pickle.dump(LNtcell_dfs, f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# open via: \n",
    "# #load updated df from pickle\n",
    "# pickle_in = open(pickle_path + \"TILtcell_dfs.pkl\",\"rb\")\n",
    "# TILtcell_dfs = pickle.load(pickle_in)\n",
    "\n",
    "# pickle_in = open(pickle_path + \"LNtcell_dfs.pkl\",\"rb\")\n",
    "# LNtcell_dfs = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741688f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
