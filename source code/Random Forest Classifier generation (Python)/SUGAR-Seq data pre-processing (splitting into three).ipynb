{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2143c82d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import csv\n",
    "import pickle #to save notebook at sessions\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#set path for pickles to be saved in\n",
    "pickle_path = '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/python pickles/'\n",
    "\n",
    "\n",
    "with open('mouse_glycogenes.pkl', 'rb') as f:\n",
    "    mouse_glycogenes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb1e31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b7c7e",
   "metadata": {},
   "source": [
    "## Defining key functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now want to add Glycosylation (PHA-L) column that assigns:\n",
    "Yes (1) to top 25%, \n",
    "No (0) to bottom 25%\n",
    "\n",
    "categorize_lectin \n",
    "inputs:\n",
    "- data_all: a dataframe that has\n",
    "    - genes in the columns headers\n",
    "    - barcodes as row indices\n",
    "    - a column with biotin values to use as cutoffs for top 25% and bottom 25%\n",
    "- quantile_high: upper quantile threshold (75% to represent top 25% of data below which 75% of the data falls)\n",
    "- quantile_low: lower quantile threshold (25% to represent bottom 25% of data below which 25% of data falls)\n",
    "- ref_col_loc: index of column in data_all that is used for categorization cutoffs\n",
    "\n",
    "outputs:\n",
    "- cutoff values for high and low biotin\n",
    "- list of 3 arrays representing indices of rows that meet the high biotin cutoff, \n",
    "low biotin cutoff, and combined high and low cutoff\n",
    "- number of rows that meet the high category cutoff and the low category cutoff.\n",
    "'''\n",
    "\n",
    "# Function: determine PHA-L read cut-offs for binary classification FROM BOJAR LAB\n",
    "def categorize_lectin(data_all, quantile_high, quantile_low, ref_col_loc):\n",
    "    cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
    "\n",
    "    print(f\"Cut-off for PHA-L high: {cutoff[0]}; Cut-off for PHA-L low: {cutoff[1]}\")\n",
    "\n",
    "    high_indices = np.array(data_all.loc[:,ref_col_loc]>=cutoff[0])\n",
    "    low_indices = np.array(data_all.loc[:,ref_col_loc]<cutoff[1])\n",
    "    high_low_indices = np.logical_or(high_indices, low_indices)\n",
    "\n",
    "    high_count = high_indices.sum()\n",
    "    low_count = low_indices.sum()\n",
    "\n",
    "    return cutoff, [high_indices, low_indices, high_low_indices], [high_count, low_count]\n",
    "\n",
    "\n",
    "'''\n",
    "Function assigns binary glycoscore to input df\n",
    "\n",
    "input:\n",
    "- c = dataframe containing normalized counts of gene expression per cell\n",
    "- Need last 2 columns to be 'Type' and 'Biotin' col\n",
    "- genes on column, cell barcodes on row \n",
    "\n",
    "output:\n",
    "- dataframe containing new column for L-PHA score \n",
    "- genes on column, barcodes on row \n",
    "'''\n",
    "\n",
    "def glycoscore(c):\n",
    "    #sort dataframe by 'Biotin values'\n",
    "    c = c.sort_values(by='Biotin', ascending=False)\n",
    "    # Parameters for categorize lectin function\n",
    "    quantile_high, quantile_low = 0.75, 0.25\n",
    "    ref_col = 'Biotin' #last column of dataframes contain biotin info\n",
    "\n",
    "    #split df into quartiles \n",
    "    cutoff, indices, count = categorize_lectin(c, quantile_high, quantile_low, ref_col)\n",
    "\n",
    "    # Assign 1 to top 25% and 0 to bottom 25%\n",
    "    c.loc[indices[0], \"PHA-L\"] = 1\n",
    "    c.loc[indices[1], \"PHA-L\"] = 0\n",
    "\n",
    "    # Drop the middle two quartiles\n",
    "    c = c.loc[indices[2], :]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fdf5e2",
   "metadata": {},
   "source": [
    "# This script randomly splits full T cell dataset into three random equally sized dataframes by cells to generate three independent models for statistical analysis for i) full transcriptome and ii) glycogene set. \n",
    "\n",
    "These dataframes are ALREADY NORMALIZED across full transcriptome, no furhter normalization required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76964620",
   "metadata": {},
   "source": [
    "## 1. Split full transcriptome\n",
    "### TILs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "489f0886",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#import dataframe that has already been normalized across full transcriptome for each T cell \u001b[39;00m\n\u001b[1;32m      2\u001b[0m pickle_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormTIL_full.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m normTIL_full \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(pickle_in)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "#import dataframe that has already been normalized across full transcriptome for each T cell \n",
    "pickle_in = open(\"normTIL_full.pkl\",\"rb\")\n",
    "normTIL_full = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIL_type_df_t = TIL_type_df_t.loc[:, ~TIL_type_df_t.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a420fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ROws must be cells, columns must be genes\n",
    "'''\n",
    "# Shuffle the rows in the original dataframe randomly\n",
    "TIL_type_shuf = TIL_type_df_t.sample(frac=1, random_state=42)\n",
    "\n",
    "# Determine the size of each dataframe\n",
    "n_rows = len(TIL_type_shuf)\n",
    "n_rows_1 = n_rows_2 = n_rows_3 = n_rows // 3\n",
    "\n",
    "# Calculate the remainder and distribute the remaining rows across the three dataframes\n",
    "remainder = n_rows % 3\n",
    "if remainder == 1:\n",
    "    n_rows_1 += 1\n",
    "elif remainder == 2:\n",
    "    n_rows_1 += 1\n",
    "    n_rows_2 += 1\n",
    "\n",
    "# Slice the shuffled dataframe into three dataframes based on the determined sizes\n",
    "TIL_type_df_1 = TIL_type_shuf.iloc[:n_rows_1]\n",
    "TIL_type_df_2 = TIL_type_shuf.iloc[n_rows_1:n_rows_1+n_rows_2]\n",
    "TIL_type_df_3 = TIL_type_shuf.iloc[n_rows_1+n_rows_2:]\n",
    "\n",
    "# Print the number of rows in each of the three dataframes\n",
    "print(len(TIL_type_df_1))\n",
    "print(len(TIL_type_df_2))\n",
    "print(len(TIL_type_df_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c165b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TIL_type_df_1.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_type_df_1, f)      \n",
    "with open('TIL_type_df_2.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_type_df_2, f)\n",
    "with open('TIL_type_df_3.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_type_df_3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f237f",
   "metadata": {},
   "source": [
    "### LNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a8f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"normLN_full.pkl\",\"rb\")\n",
    "normLN_full = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e249488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate columns\n",
    "LN_type_df_t = LN_type_df_t.loc[:, ~LN_type_df_t.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the rows in the original dataframe randomly\n",
    "LN_type_shuf = LN_type_df_t.sample(frac=1, random_state=42)\n",
    "\n",
    "# Determine the size of each dataframe\n",
    "n_rows = len(LN_type_shuf)\n",
    "n_rows_1 = n_rows_2 = n_rows_3 = n_rows // 3\n",
    "\n",
    "# Calculate the remainder and distribute the remaining rows across the three dataframes\n",
    "remainder = n_rows % 3\n",
    "if remainder == 1:\n",
    "    n_rows_1 += 1\n",
    "elif remainder == 2:\n",
    "    n_rows_1 += 1\n",
    "    n_rows_2 += 1\n",
    "\n",
    "# Slice the shuffled dataframe into three dataframes based on the determined sizes\n",
    "LN_type_df_1 = LN_type_shuf.iloc[:n_rows_1]\n",
    "LN_type_df_2 = LN_type_shuf.iloc[n_rows_1:n_rows_1+n_rows_2]\n",
    "LN_type_df_3 = LN_type_shuf.iloc[n_rows_1+n_rows_2:]\n",
    "\n",
    "# Print the number of rows in each of the three dataframes\n",
    "print(len(LN_type_df_1))\n",
    "print(len(LN_type_df_2))\n",
    "print(len(LN_type_df_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd94b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LN_type_df_1.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_type_df_1, f)      \n",
    "with open('LN_type_df_2.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_type_df_2, f)\n",
    "with open('LN_type_df_3.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_type_df_3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96b0fa",
   "metadata": {},
   "source": [
    "## Glycoscore each subset of data for full transcriptome "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a1a15e",
   "metadata": {},
   "source": [
    "### for TILs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862318b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Assign glycoscores to each cell. \n",
    "INPUT df must have genes, biotin score, and type in columns and cells in rows\n",
    "'''\n",
    "with open('TIL_type_df_1.pkl', 'rb') as f:\n",
    "    TIL_type_df_1 = pickle.load(f)\n",
    "    \n",
    "TIL_glyconorm_1 = glycoscore(TIL_type_df_1)\n",
    "\n",
    "with open('TIL_glyconorm_1.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_glyconorm_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f69581",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TIL_type_df_2.pkl', 'rb') as f:\n",
    "    TIL_type_df_2 = pickle.load(f)\n",
    "\n",
    "TIL_glyconorm_2 = glycoscore(TIL_type_df_2)\n",
    "\n",
    "with open('TIL_glyconorm_2.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_glyconorm_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TIL_type_df_3.pkl', 'rb') as f:\n",
    "    TIL_type_df_3 = pickle.load(f)\n",
    "    \n",
    "TIL_glyconorm_3 = glycoscore(TIL_type_df_3)\n",
    "\n",
    "with open('TIL_glyconorm_3.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_glyconorm_3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e044b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dictionary that contains the three dataframes\n",
    "TILglyconorm_split = {}\n",
    "TILglyconorm_split['1']= TIL_glyconorm_1\n",
    "TILglyconorm_split['2']= TIL_glyconorm_2\n",
    "TILglyconorm_split['3']= TIL_glyconorm_3\n",
    "\n",
    "with open('TILglyconorm_split.pkl', 'wb') as f:\n",
    "    pickle.dump(TILglyconorm_split, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a058e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TILglyconorm_split.pkl', 'wb') as f:\n",
    "    TILglyconorm_split = pickle.load(f)\n",
    "TILglyconorm_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73df8ab",
   "metadata": {},
   "source": [
    "### for LNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e10424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LN_type_df_1.pkl', 'rb') as f:\n",
    "    LN_type_df_1 = pickle.load(f)    \n",
    "    \n",
    "LN_glyconorm_1 = glycoscore(LN_type_df_1)\n",
    "with open('LN_glyconorm_1.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_glyconorm_1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51858843",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LN_type_df_2.pkl', 'rb') as f:\n",
    "    LN_type_df_2 = pickle.load(f)    \n",
    "LN_glyconorm_2 = glycoscore(LN_type_df_2)\n",
    "with open('LN_glyconorm_2.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_glyconorm_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('normLN_full_3.pkl', 'rb') as f:\n",
    "    normLN_3 = pickle.load(f)    \n",
    "LN_glyconorm_3 = glycoscore(normLN_3)\n",
    "with open('LN_glyconorm_3.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_glyconorm_3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ada307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dictionary that contains the three dataframes\n",
    "LNglyconorm_split = {}\n",
    "LNglyconorm_split['1']= LN_glyconorm_1\n",
    "LNglyconorm_split['2']= LN_glyconorm_2\n",
    "LNglyconorm_split['3']= LN_glyconorm_3\n",
    "\n",
    "with open('LNglyconorm_split.pkl', 'wb') as f:\n",
    "    pickle.dump(LNglyconorm_split, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a717c5",
   "metadata": {},
   "source": [
    "\n",
    "#### LNglyconorm_split and TILglyconorm_split\n",
    "are dictionaries that contain three dataframes of equal sizes that have been normalized previously across\n",
    "full dataset and glycoscored\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0e141",
   "metadata": {},
   "source": [
    "# 2. Filter split datasets to only include glycogenes (incl. housekeeping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4104a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These dataframes have genes+biotin+type+glycoscore in columns and cells in rows\n",
    "these dataframes ARE normalized already (normalized once before splitting)\n",
    "'''\n",
    "with open('TILglyconorm_split.pkl', 'rb') as f:\n",
    "    TILglyconorm_split = pickle.load(f)\n",
    "with open('LNglyconorm_split.pkl', 'rb') as f:\n",
    "    LNglyconorm_split = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96922652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of glycogenes looked for: 245\n",
      "Number of glycogenes found in TILs: 240\n",
      "Number of glycogenes found in TILs: 240\n",
      "Number of glycogenes found in TILs: 240\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "filter the original matrix by the mouse glycogenes but keep biotin, type info\n",
    "NOTE: input dataframe must have genes in rows and cells in columns\n",
    "\n",
    "output: list of dfs that have been filtered for glycogenes\n",
    "'''\n",
    "print('Total number of glycogenes looked for:', len(mouse_glycogenes))\n",
    "\n",
    "#TIL\n",
    "TIL1 = TIL_type_df_1.transpose()\n",
    "TIL2 = TIL_type_df_2.transpose()\n",
    "TIL3 = TIL_type_df_3.transpose()\n",
    "TIL_dfs = [TIL1, TIL2, TIL3]\n",
    "glycoTIL_dfs = []\n",
    "\n",
    "for df in TIL_dfs:\n",
    "    found = [i for i in mouse_glycogenes if i in df.index]\n",
    "    notfound = [i for i in mouse_glycogenes if i not in df.index]\n",
    "    glyco_df = df.loc[found + ['Biotin', 'Type', 'PHA-L']] \n",
    "    print('Number of glycogenes found in TILs:', len(glyco_df)-3) #-2 accounts for extra type, biotin, score rows\n",
    "    glycoTIL_dfs.append(glyco_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dfe12dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of glycogenes found in LNs: 240\n",
      "Number of glycogenes found in LNs: 240\n",
      "Number of glycogenes found in LNs: 240\n"
     ]
    }
   ],
   "source": [
    "#LN\n",
    "LN_type_df_1 = LN_type_df_1.rename(columns = {'Biotin_hash':'Biotin'})\n",
    "LN_type_df_2 = LN_type_df_2.rename(columns = {'Biotin_hash':'Biotin'})\n",
    "LN_type_df_3 = LN_type_df_3.rename(columns = {'Biotin_hash':'Biotin'})\n",
    "\n",
    "LN1 = LN_type_df_1.transpose()\n",
    "LN2 = LN_type_df_2.transpose()\n",
    "LN3 = LN_type_df_3.transpose()\n",
    "LN_dfs = [LN1, LN2, LN3]\n",
    "glycoLN_dfs = []\n",
    "\n",
    "for df in LN_dfs:\n",
    "    found = [i for i in mouse_glycogenes if i in df.index]\n",
    "    notfound = [i for i in mouse_glycogenes if i not in df.index]\n",
    "    glyco_df = df.loc[found + ['Biotin', 'Type', 'PHA-L']]\n",
    "    print('Number of glycogenes found in LNs:', len(glyco_df)-3) #-3 accounts for extra type, biotin, score rows\n",
    "    glycoLN_dfs.append(glyco_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862028c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glycoTIL_dict = {}\n",
    "glycoTIL_dict['1'] = glycoTIL_dfs[0]\n",
    "glycoTIL_dict['2'] = glycoTIL_dfs[1]\n",
    "glycoTIL_dict['3'] = glycoTIL_dfs[2]\n",
    "\n",
    "glycoLN_dict = {}\n",
    "glycoLN_dict['1'] = glycoLN_dfs[0]\n",
    "glycoLN_dict['2'] = glycoLN_dfs[1]\n",
    "glycoLN_dict['3'] = glycoLN_dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e50833",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('glycoTIL_normscored_split.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoTIL_normscored_split, f)  \n",
    "with open('glycoLN_normscored_split.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoLN_normscored_split, f)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
