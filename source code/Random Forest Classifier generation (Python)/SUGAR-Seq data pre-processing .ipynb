{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2143c82d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import csv\n",
    "import pickle #to save notebook at sessions\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#set path for pickles to be saved in\n",
    "pickle_path = '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/python pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb1e31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068cec0",
   "metadata": {},
   "source": [
    "# What is going on (on raw counts)\n",
    "1. Import glycogene csv of human glycogenes converted to mice homologs (because our data is from mice tumor models. Human glycogenes are from glyco.me (Glycopacity). \n",
    "2. Load barcodes, features, and matrix of LN and TILs and convert to dataframe\n",
    "3. Import transformed identity csv with info on which cells are associated with which cell type\n",
    "4. Filter cells from original dataframe to produce smaller dataframe of just TILs in LN/TIL population from transformed identity csv\n",
    "5. Filter genes from filtered dataframe (from 4) to only include glycogenes from (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac3d0e",
   "metadata": {},
   "source": [
    "## 1. Import human to mouse glycogene csv.\n",
    "Converted human glycogenes to their mouse homologs via https://www.informatics.jax.org/batch/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a61d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load mouse glycogenes \n",
    "\n",
    "glyco_fp = 'human to mouse glycogene converted.csv'\n",
    "glycogene_df = pd.read_csv(glyco_fp)\n",
    "\n",
    "#make mouse glycogene list\n",
    "m_glyco = glycogene_df[['Mouse']]\n",
    "mouse_glyco_long = list(m_glyco.dropna(axis=0)['Mouse']) #removed 3 genes that didn't have mice homologs\n",
    "\n",
    "#export just the mouse glycogenes as csv\n",
    "m_glyco.to_csv('Mouse glycogenes.csv')\n",
    "\n",
    "# remove duplicates\n",
    "mouse_glycogenes = set(mouse_glyco_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5001ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle list of mouse glycogenes\n",
    "with open('mouse_glycogenes.pkl', 'wb') as f:\n",
    "    pickle.dump(mouse_glycogenes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90fdba",
   "metadata": {},
   "source": [
    "## 2. Load barcodes, features, and matrix of LN and TILs and convert to dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd05562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TAKES LONG TIME TO RUN!! ## \n",
    "# Load the LN SUGAR-seq matrix from file\n",
    "sparse_LN = sp.io.mmread(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/matrix.mtx')\n",
    "# Convert to CSR format\n",
    "sparse_LN = sp.sparse.csr_matrix(sparse_LN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c2b8b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_72324/477600803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## TAKES LONG TIME TO RUN!! ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load the TIL SUGAR-seq matrix from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m sparse_TIL = sp.io.mmread(\n\u001b[0m\u001b[1;32m      4\u001b[0m     '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx')\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert to CSR format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/io/_mmio.py\u001b[0m in \u001b[0;36mmmread\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMMFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/io/_mmio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/io/_mmio.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(filespec, mode)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilespec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilespec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# open for writing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx'"
     ]
    }
   ],
   "source": [
    "## TAKES LONG TIME TO RUN!! ## \n",
    "# Load the TIL SUGAR-seq matrix from file\n",
    "sparse_TIL = sp.io.mmread(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx')\n",
    "# Convert to CSR format\n",
    "sparse_TIL = sp.sparse.csr_matrix(sparse_TIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension check of sparse matrix\n",
    "print('LN matrix dimesions are', np.shape(sparse_LN)) #31059 = rows , 21343=columns\n",
    "print('TIL matrix dimesions are', np.shape(sparse_TIL))\n",
    "\n",
    "# convert sparse matrices to array to put into dataframe\n",
    "LN_matrix = sparse_LN.toarray()\n",
    "TIL_matrix = sparse_TIL.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d82de",
   "metadata": {},
   "source": [
    "### Set up data frame for TIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807dfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TIL data ##  \n",
    "# barcodes = row names\n",
    "barcodes = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/barcodes copy.tsv', \n",
    "    header=None)\n",
    "barcodes = barcodes.rename(columns={0: 'barcode'})\n",
    "TIL_barcodes = list(barcodes['barcode']) # of columns =  21343\n",
    "\n",
    "# features = column names\n",
    "feats = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/features.tsv', \n",
    "    header = None)\n",
    "with open('/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/features.tsv', \n",
    "          'r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    feat_ls = []\n",
    "    for row in reader:\n",
    "        feat_ls.append(row)\n",
    "TIL_features = [i[1] for i in feat_ls] # of rows = 31059\n",
    "\n",
    "# Convert the dense matrix to a pandas DataFrame\n",
    "TIL_df = pd.DataFrame(data=TIL_matrix, index=TIL_features, columns=TIL_barcodes)\n",
    "\n",
    "# Remove rows for HTO1, HTO2, PD1, and TIM3 (ADT and HTO assays)\n",
    "TIL_df_new = TIL_df.drop(['HTO1', 'HTO2','PD1', 'TIM3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f68f99",
   "metadata": {},
   "source": [
    "### set up dataframe for LN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a23ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LN data ## \n",
    "# barcodes = row names\n",
    "barcodes = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/barcodes copy.tsv', \n",
    "    header=None)\n",
    "barcodes = barcodes.rename(columns={0: 'barcode'})\n",
    "LN_barcodes = list(barcodes['barcode']) # of columns =  21343\n",
    "\n",
    "# features = column names\n",
    "feats = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/features.tsv', header = None)\n",
    "with open('/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/features.tsv', \n",
    "          'r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    feat_ls = []\n",
    "    for row in reader:\n",
    "        feat_ls.append(row)\n",
    "LN_features = [i[1] for i in feat_ls] # of rows = 31059\n",
    "\n",
    "# Convert the dense matrix to a pandas DataFrame with columns as each barcode and rows as each gene\n",
    "LN_df = pd.DataFrame(data=LN_matrix, index=LN_features, columns=LN_barcodes)\n",
    "\n",
    "# Remove rows for HTO1, HTO2, PD1, and TIM3 (ADT and HTO assays)\n",
    "LN_df_new = LN_df.drop(['hashtag1', 'hashtag2','hashtag3', 'PD1_hash', 'TIM3_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL df set up.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_df_new, f)\n",
    "    \n",
    "with open(pickle_path + 'LN df set up.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_df_new, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f52bf",
   "metadata": {},
   "source": [
    "## 3. Add cell type info from csv exported from ProjecTIL cell type annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa85488",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL df set up.pkl', 'rb') as f:\n",
    "    TIL_df_new = pickle.load(f)\n",
    "\n",
    "with open(pickle_path + 'LN df set up.pkl', 'rb') as f:\n",
    "    LN_df_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c9a133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#check to see St6galnac2 -->  non-identical columns but named the same \n",
    "n = TIL_df_new.transpose()\n",
    "n = n.filter(regex='^St6galnac2$')\n",
    "names = ['1','2']\n",
    "n.columns = names\n",
    "n\n",
    "print(n['1'].equals(n['2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdbfeec",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/TIL output/ProjecTIL analysis/TIL_transformed_identity.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_17060/1230910064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# import ProjecTIL analysis output to add cell type annotation to raw glycogene data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mTIL_transformed_ident\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_TIL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mLN_transformed_ident\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_LN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/TIL output/ProjecTIL analysis/TIL_transformed_identity.csv'"
     ]
    }
   ],
   "source": [
    "path_TIL='/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/TIL output/ProjecTIL analysis/TIL_transformed_identity.csv'\n",
    "path_LN='/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/LN output/ProjecTIL analysis/LN_transformed_identity.csv'\n",
    "\n",
    "# import ProjecTIL analysis output to add cell type annotation to raw glycogene data frame \n",
    "TIL_transformed_ident = pd.read_csv(path_TIL)\n",
    "LN_transformed_ident = pd.read_csv(path_LN)\n",
    "\n",
    "#rename column of ProjecTIL df for easy identification of barcodes\n",
    "TIL_transformed_ident = TIL_transformed_ident.rename(columns={'Unnamed: 0':'Barcodes'}) \n",
    "LN_transformed_ident = LN_transformed_ident.rename(columns={'Unnamed: 0':'Barcodes'}) \n",
    "\n",
    "#Transpose matrix to match final TIL/LN matrix format\n",
    "TIL_transformed_ident = TIL_transformed_ident.transpose()\n",
    "LN_transformed_ident = LN_transformed_ident.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1dd9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUn only once, else it keeps replacing index with top row. if you run too much, rerun previous cell first!! \n",
    "'''\n",
    "make the column names the barcodes, which is how the glycogene \n",
    "dataframe (the one we want to combine this one with) is formatted as, to concatenate\n",
    "'''\n",
    "TIL_transformed_ident.set_axis(TIL_transformed_ident.iloc[0], axis=1, inplace=True)\n",
    "TIL_transformed_ident = TIL_transformed_ident[1:] \n",
    "\n",
    "LN_transformed_ident.set_axis(LN_transformed_ident.iloc[0], axis=1, inplace=True)\n",
    "LN_transformed_ident = LN_transformed_ident[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as binarized pickle file \n",
    "with open(pickle_path + 'TIL_transformed_ident.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_transformed_ident, f)\n",
    "    \n",
    "with open(pickle_path + 'LN_transformed_ident.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_transformed_ident, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5e874",
   "metadata": {},
   "source": [
    "### Remove non-TILs from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5049fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe dimensions are  (31054, 19912) and the filtered dataframe dimensions are (31054, 19645)\n",
      "Original dataframe dimensions are  (31054, 21343) and the filtered dataframe dimensions are (31054, 21296)\n"
     ]
    }
   ],
   "source": [
    "# # filter original matrix by barcodes of cells identified as TILs via ProjecTILs #\n",
    "\n",
    "# extract list of barcodes that have a T-cell annotation\n",
    "TIL_barcodes = list(TIL_transformed_ident.columns)\n",
    "LN_barcodes = list(LN_transformed_ident.columns)\n",
    "\n",
    "\n",
    "filtered_TIL_df = TIL_df_new[TIL_barcodes]\n",
    "filtered_LN_df = LN_df_new[LN_barcodes]\n",
    "\n",
    "print('Original dataframe dimensions are ', TIL_df_new.shape, \n",
    "      'and the filtered dataframe dimensions are', filtered_TIL_df.shape)\n",
    "print('Original dataframe dimensions are ', LN_df_new.shape, \n",
    "      'and the filtered dataframe dimensions are', filtered_LN_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as binarized pickle file \n",
    "with open(pickle_path + 'filtered_TIL_df.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_TIL_df, f)\n",
    "    \n",
    "with open(pickle_path + 'filtered_LN_df.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_LN_df, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97ec8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##TAKES LONG TIME TO RUN##\n",
    "'''\n",
    "Add cell type information via concatenation\n",
    "Note: the L-Pha information from this csv is normalized, and since we're using raw data we'll use the raw biotin info\n",
    "'''\n",
    "TIL_type = TIL_transformed_ident.loc[['Type']]\n",
    "LN_type = LN_transformed_ident.loc[['Type']]\n",
    "\n",
    "#makes new dataframe that adds T-cell type annotations to raw gene expression dataframe \n",
    "TIL_type_df = pd.concat([filtered_TIL_df, TIL_type])\n",
    "LN_type_df = pd.concat([filtered_LN_df, LN_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd39b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL_type_df.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_type_df, f)\n",
    "    \n",
    "with open(pickle_path + 'LN_type_df.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_type_df, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fdf5e2",
   "metadata": {},
   "source": [
    "## 4. DO normalization of T-cells via full transcriptome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489f0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TIL_type_df.pkl', 'rb') as f:\n",
    "    TIL_type_df = pickle.load(f)\n",
    "\n",
    "# with open('LN_type_df.pkl', 'rb') as f:\n",
    "#     LN_type_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34df235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAACCTGAGAATTGTG-1</th>\n",
       "      <th>AAACCTGAGAGACTAT-1</th>\n",
       "      <th>AAACCTGAGAGGGATA-1</th>\n",
       "      <th>AAACCTGAGATCTGAA-1</th>\n",
       "      <th>AAACCTGAGCCTATGT-1</th>\n",
       "      <th>AAACCTGAGCGTAGTG-1</th>\n",
       "      <th>AAACCTGAGCTCCTTC-1</th>\n",
       "      <th>AAACCTGAGGCGATAC-1</th>\n",
       "      <th>AAACCTGAGGGATCTG-1</th>\n",
       "      <th>AAACCTGAGGGTCGAT-1</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTGTCAGTGTTCGAT-1</th>\n",
       "      <th>TTTGTCAGTTTGTTTC-1</th>\n",
       "      <th>TTTGTCATCAACACCA-1</th>\n",
       "      <th>TTTGTCATCAATAAGG-1</th>\n",
       "      <th>TTTGTCATCAGAGCTT-1</th>\n",
       "      <th>TTTGTCATCCGCATCT-1</th>\n",
       "      <th>TTTGTCATCGGCATCG-1</th>\n",
       "      <th>TTTGTCATCTAACCGA-1</th>\n",
       "      <th>TTTGTCATCTTAACCT-1</th>\n",
       "      <th>TTTGTCATCTTGAGAC-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Xkr4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gm1992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gm37381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rp1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sox17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAAA01118383.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vmn2r122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAAA01147332.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biotin_hash</th>\n",
       "      <td>223</td>\n",
       "      <td>124</td>\n",
       "      <td>404</td>\n",
       "      <td>138</td>\n",
       "      <td>1080</td>\n",
       "      <td>232</td>\n",
       "      <td>252</td>\n",
       "      <td>173</td>\n",
       "      <td>186</td>\n",
       "      <td>536</td>\n",
       "      <td>...</td>\n",
       "      <td>236</td>\n",
       "      <td>86</td>\n",
       "      <td>149</td>\n",
       "      <td>95</td>\n",
       "      <td>140</td>\n",
       "      <td>159</td>\n",
       "      <td>196</td>\n",
       "      <td>152</td>\n",
       "      <td>88</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD4_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_EarlyActiv</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>...</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31055 rows × 21296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AAACCTGAGAATTGTG-1 AAACCTGAGAGACTAT-1 AAACCTGAGAGGGATA-1   \n",
       "Xkr4                            0                  0                  0  \\\n",
       "Gm1992                          0                  0                  0   \n",
       "Gm37381                         0                  0                  0   \n",
       "Rp1                             0                  0                  0   \n",
       "Sox17                           0                  0                  0   \n",
       "...                           ...                ...                ...   \n",
       "CAAA01118383.1                  0                  0                  0   \n",
       "Vmn2r122                        0                  0                  0   \n",
       "CAAA01147332.1                  0                  0                  0   \n",
       "Biotin_hash                   223                124                404   \n",
       "Type                CD8_NaiveLike      CD4_NaiveLike      CD8_NaiveLike   \n",
       "\n",
       "               AAACCTGAGATCTGAA-1 AAACCTGAGCCTATGT-1 AAACCTGAGCGTAGTG-1   \n",
       "Xkr4                            0                  0                  0  \\\n",
       "Gm1992                          0                  0                  0   \n",
       "Gm37381                         0                  0                  0   \n",
       "Rp1                             0                  0                  0   \n",
       "Sox17                           0                  0                  0   \n",
       "...                           ...                ...                ...   \n",
       "CAAA01118383.1                  1                  0                  0   \n",
       "Vmn2r122                        0                  0                  0   \n",
       "CAAA01147332.1                  0                  0                  0   \n",
       "Biotin_hash                   138               1080                232   \n",
       "Type                CD8_NaiveLike     CD8_EarlyActiv      CD8_NaiveLike   \n",
       "\n",
       "                AAACCTGAGCTCCTTC-1 AAACCTGAGGCGATAC-1 AAACCTGAGGGATCTG-1   \n",
       "Xkr4                             0                  0                  0  \\\n",
       "Gm1992                           0                  0                  0   \n",
       "Gm37381                          0                  0                  0   \n",
       "Rp1                              0                  0                  0   \n",
       "Sox17                            0                  0                  0   \n",
       "...                            ...                ...                ...   \n",
       "CAAA01118383.1                   1                  0                  1   \n",
       "Vmn2r122                         0                  0                  0   \n",
       "CAAA01147332.1                   0                  0                  0   \n",
       "Biotin_hash                    252                173                186   \n",
       "Type            CD8_EffectorMemory      CD8_NaiveLike      CD8_NaiveLike   \n",
       "\n",
       "               AAACCTGAGGGTCGAT-1  ... TTTGTCAGTGTTCGAT-1 TTTGTCAGTTTGTTTC-1   \n",
       "Xkr4                            0  ...                  0                  0  \\\n",
       "Gm1992                          0  ...                  0                  0   \n",
       "Gm37381                         0  ...                  0                  0   \n",
       "Rp1                             0  ...                  0                  0   \n",
       "Sox17                           0  ...                  0                  0   \n",
       "...                           ...  ...                ...                ...   \n",
       "CAAA01118383.1                  0  ...                  0                  0   \n",
       "Vmn2r122                        0  ...                  0                  0   \n",
       "CAAA01147332.1                  0  ...                  0                  0   \n",
       "Biotin_hash                   536  ...                236                 86   \n",
       "Type                CD8_NaiveLike  ...      CD8_NaiveLike      CD8_NaiveLike   \n",
       "\n",
       "               TTTGTCATCAACACCA-1 TTTGTCATCAATAAGG-1 TTTGTCATCAGAGCTT-1   \n",
       "Xkr4                            0                  0                  0  \\\n",
       "Gm1992                          0                  0                  0   \n",
       "Gm37381                         0                  0                  0   \n",
       "Rp1                             0                  0                  0   \n",
       "Sox17                           0                  0                  0   \n",
       "...                           ...                ...                ...   \n",
       "CAAA01118383.1                  0                  0                  1   \n",
       "Vmn2r122                        0                  0                  0   \n",
       "CAAA01147332.1                  0                  0                  0   \n",
       "Biotin_hash                   149                 95                140   \n",
       "Type                CD8_NaiveLike      CD8_NaiveLike      CD8_NaiveLike   \n",
       "\n",
       "               TTTGTCATCCGCATCT-1 TTTGTCATCGGCATCG-1 TTTGTCATCTAACCGA-1   \n",
       "Xkr4                            0                  0                  0  \\\n",
       "Gm1992                          0                  0                  0   \n",
       "Gm37381                         0                  0                  0   \n",
       "Rp1                             0                  0                  0   \n",
       "Sox17                           0                  0                  0   \n",
       "...                           ...                ...                ...   \n",
       "CAAA01118383.1                  0                  1                  0   \n",
       "Vmn2r122                        0                  0                  0   \n",
       "CAAA01147332.1                  0                  0                  1   \n",
       "Biotin_hash                   159                196                152   \n",
       "Type                CD8_NaiveLike      CD8_NaiveLike      CD8_NaiveLike   \n",
       "\n",
       "               TTTGTCATCTTAACCT-1 TTTGTCATCTTGAGAC-1  \n",
       "Xkr4                            0                  0  \n",
       "Gm1992                          0                  0  \n",
       "Gm37381                         0                  0  \n",
       "Rp1                             0                  0  \n",
       "Sox17                           0                  0  \n",
       "...                           ...                ...  \n",
       "CAAA01118383.1                  0                  0  \n",
       "Vmn2r122                        0                  0  \n",
       "CAAA01147332.1                  0                  0  \n",
       "Biotin_hash                    88                124  \n",
       "Type                CD8_NaiveLike      CD8_NaiveLike  \n",
       "\n",
       "[31055 rows x 21296 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LN_type_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9ada89",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Perform robust scaler normalization\n",
    "\n",
    "This defines a function that normalizes expression across the different genes for each cell.\n",
    "\n",
    "input:\n",
    "- df with last 2 rows that are type, biotin\n",
    "- rows = genes, columns = cells\n",
    "\n",
    "output:\n",
    "- scaled df with same dimensions\n",
    "- df with columns as genes and rows as cells\n",
    "'''\n",
    "\n",
    "def robust_normalization(df):\n",
    "    ## isolate just gene columns and standardize \n",
    "    toy_df = df.iloc[:-2]\n",
    "    cols_to_standardize = toy_df.columns\n",
    "    scaler = RobustScaler()\n",
    "    toy_df[cols_to_standardize] = scaler.fit_transform(toy_df[cols_to_standardize])\n",
    "    \n",
    "    ## extract biotin, t-cell type, and L-PHA data from original dataframe and append to transformed data\n",
    "    scores_to_append = df.iloc[-2:]\n",
    "\n",
    "    norm_df = pd.concat([toy_df, scores_to_append])\n",
    "    norm_df = norm_df.transpose()\n",
    "   \n",
    "    return norm_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d87d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now want to add Glycosylation (PHA-L) column that assigns:\n",
    "Yes (1) to top 25%, \n",
    "No (0) to bottom 25%\n",
    "\n",
    "categorize_lectin \n",
    "inputs:\n",
    "- data_all: a dataframe that has\n",
    "    - genes in the columns headers\n",
    "    - barcodes as row indices\n",
    "    - a column with biotin values to use as cutoffs for top 25% and bottom 25%\n",
    "- quantile_high: upper quantile threshold (75% to represent top 25% of data below which 75% of the data falls)\n",
    "- quantile_low: lower quantile threshold (25% to represent bottom 25% of data below which 25% of data falls)\n",
    "- ref_col_loc: index of column in data_all that is used for categorization cutoffs\n",
    "\n",
    "outputs:\n",
    "- cutoff values for high and low biotin\n",
    "- list of 3 arrays representing indices of rows that meet the high biotin cutoff, \n",
    "low biotin cutoff, and combined high and low cutoff\n",
    "- number of rows that meet the high category cutoff and the low category cutoff.\n",
    "'''\n",
    "\n",
    "# Function: determine PHA-L read cut-offs for binary classification FROM BOJAR LAB\n",
    "def categorize_lectin(data_all, quantile_high, quantile_low, ref_col_loc):\n",
    "    cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
    "\n",
    "    print(f\"Cut-off for PHA-L high: {cutoff[0]}; Cut-off for PHA-L low: {cutoff[1]}\")\n",
    "\n",
    "    high_indices = np.array(data_all.loc[:,ref_col_loc]>=cutoff[0])\n",
    "    low_indices = np.array(data_all.loc[:,ref_col_loc]<cutoff[1])\n",
    "    high_low_indices = np.logical_or(high_indices, low_indices)\n",
    "\n",
    "    high_count = high_indices.sum()\n",
    "    low_count = low_indices.sum()\n",
    "\n",
    "    return cutoff, [high_indices, low_indices, high_low_indices], [high_count, low_count]\n",
    "\n",
    "\n",
    "'''\n",
    "Function assigns binary glycoscore to input df\n",
    "\n",
    "input:\n",
    "- c = dataframe containing normalized counts of gene expression per cell\n",
    "- Need last 2 columns to be 'Type' and 'Biotin' col\n",
    "- genes on column, cell barcodes on row \n",
    "\n",
    "output:\n",
    "- dataframe containing new column for L-PHA score \n",
    "- genes on column, barcodes on row \n",
    "'''\n",
    "\n",
    "def glycoscore(c):\n",
    "    #sort dataframe by 'Biotin values'\n",
    "    c = c.sort_values(by='Biotin', ascending=False)\n",
    "    # Parameters for categorize lectin function\n",
    "    quantile_high, quantile_low = 0.75, 0.25\n",
    "    ref_col = 'Biotin' #last column of dataframes contain biotin info\n",
    "\n",
    "    #split df into quartiles \n",
    "    cutoff, indices, count = categorize_lectin(c, quantile_high, quantile_low, ref_col)\n",
    "\n",
    "    # Assign 1 to top 25% and 0 to bottom 25%\n",
    "    c.loc[indices[0], \"PHA-L\"] = 1\n",
    "    c.loc[indices[1], \"PHA-L\"] = 0\n",
    "\n",
    "    # Drop the middle two quartiles\n",
    "    c = c.loc[indices[2], :]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2757b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = TIL.transpose(a)\n",
    "n = n.filter(regex='^St6galnac2$')\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5bd5719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2727/106849003.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  toy_df[cols_to_standardize] = scaler.fit_transform(toy_df[cols_to_standardize])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Normalize gene counts across all genes for each T-cell\n",
    "\n",
    "recall robust normalization will spit out TRANSPOSED dataframe\n",
    "TAKES FOREVER\n",
    "'''\n",
    "normTIL = robust_normalization(TIL_type_df)\n",
    "# normLN = robust_normalization(LN_type_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d444806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Biotin_hash column in LN dataframe to 'Biotin' for easy glycoscoring via glycoscore function\n",
    "pre_scoredLN = normLN.rename(columns={'Biotin_hash': 'Biotin'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "724380d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('normTIL_full.pkl', 'wb') as f:\n",
    "    pickle.dump(normTIL, f)\n",
    "\n",
    "# with open('normLN_full.pkl', 'wb') as f:\n",
    "#     pickle.dump(pre_scoredLN, f)\n",
    "\n",
    "# pickle_in = open(\"normTIL_full.pkl\",\"rb\")\n",
    "# normTIL_full = pickle.load(pickle_in)\n",
    "# pickle_in = open(\"normLN_full.pkl\",\"rb\")\n",
    "# normLN_full = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2afd38b",
   "metadata": {},
   "source": [
    "## Glycoscoring of normalized dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "862318b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7394/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off for PHA-L high: 276; Cut-off for PHA-L low: 127\n"
     ]
    }
   ],
   "source": [
    "# Assign glycoscores to each cell\n",
    "#TIL_glyconorm = = glycoscore(pre_scoredTIL)\n",
    "LN_glyconorm = glycoscore(pre_scoredLN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b716499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle of df\n",
    "# with open('full_TIL_glyconorm.pkl', 'wb') as f:\n",
    "#     pickle.dump(TIL_glyconorm, f)\n",
    "\n",
    "with open('full_LN_glyconorm.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_glyconorm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0e141",
   "metadata": {},
   "source": [
    "## 5. Filter matrix to only include glycogenes (incl. housekeeping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4104a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These dataframes have genes+biotin+type+glycoscore in columns and cells in rows\n",
    "'''\n",
    "#from JEssie\n",
    "with open('full_TIL_glyconorm.pkl', 'rb') as f:\n",
    "    TIL_type_df = pickle.load(f)\n",
    "\n",
    "with open('full_LN_glyconorm.pkl', 'rb') as f:\n",
    "    LN_type_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccd79b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIL = TIL_type_df.transpose()\n",
    "LN = LN_type_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96922652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of glycogenes looked for: 245\n",
      "Number of glycogenes found in TILs: 9821\n",
      "Number of glycogenes found in LNs: 241\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "filter the original matrix by the mouse glycogenes but keep biotin and type info\n",
    "\n",
    "NOTE: input dataframe must have genes in rows and cells in columns\n",
    "'''\n",
    "print('Total number of glycogenes looked for:', len(mouse_glycogenes))\n",
    "\n",
    "#TIL\n",
    "TILglycogenes_found = [i for i in mouse_glycogenes if i in TIL.index]\n",
    "TILglycogenes_notfound = [i for i in mouse_glycogenes if i not in TIL.index]\n",
    "\n",
    "#filter by glycogenes while keeping type&biotin&glycoscore\n",
    "glycoTIL = TIL.loc[TILglycogenes_found + ['Biotin', 'Type', 'PHA-L']] \n",
    "print('Number of glycogenes found in TILs:', len(glycoTIL_df)-3) #-3 accounts for extra type, biotin, PHA-L rows\n",
    "\n",
    "\n",
    "#LN\n",
    "LNglycogenes_found = [i for i in mouse_glycogenes if i in LN.index]\n",
    "LNglycogenes_notfound = [i for i in mouse_glycogenes if i not in LN.index]\n",
    "\n",
    "glycoLN = LN.loc[LNglycogenes_found + ['Biotin', 'Type', 'PHA-L']] \n",
    "print('Number of glycogenes found in LNs:', len(glycoLN_df) - 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49902ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Galnt13</th>\n",
       "      <th>B3gnt2</th>\n",
       "      <th>Gcnt2</th>\n",
       "      <th>A4galt</th>\n",
       "      <th>St3gal4</th>\n",
       "      <th>St8sia1</th>\n",
       "      <th>Extl2</th>\n",
       "      <th>Plod3</th>\n",
       "      <th>B3gnt7</th>\n",
       "      <th>Dpy19l1</th>\n",
       "      <th>...</th>\n",
       "      <th>Chpf2</th>\n",
       "      <th>Mgat4d</th>\n",
       "      <th>Bcap31</th>\n",
       "      <th>Pomt2</th>\n",
       "      <th>St8sia2</th>\n",
       "      <th>Alg10b</th>\n",
       "      <th>Piga</th>\n",
       "      <th>Biotin</th>\n",
       "      <th>Type</th>\n",
       "      <th>PHA-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TACAGTGGTTCAACCA-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37384</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACATACGAGTGCCATT-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33249</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGTCCCATCGGCTTGG-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32029</td>\n",
       "      <td>Th1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTGTCCAGGATGGTC-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31700</td>\n",
       "      <td>CD8_EarlyActiv</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAACATCTCTGCTGTC-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31402</td>\n",
       "      <td>Treg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGTCAGGGTTTGACAC-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGGTCTCGAACTGT-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCTGCTTCACCAACCG-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGGTTCCGTTGATTCG-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTGCGGACACGAAGCA-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9824 rows × 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Galnt13 B3gnt2 Gcnt2 A4galt St3gal4 St8sia1 Extl2 Plod3   \n",
       "TACAGTGGTTCAACCA-1     0.0    0.0   0.0    0.0     0.0     0.0   0.0   0.0  \\\n",
       "ACATACGAGTGCCATT-1     0.0    1.0   0.0    0.0     0.0     0.0   0.0   0.0   \n",
       "TGTCCCATCGGCTTGG-1     0.0    1.0   0.0    0.0     0.0     0.0   0.0   0.0   \n",
       "ACTGTCCAGGATGGTC-1     0.0    0.0   1.0    0.0     0.0     0.0   0.0   0.0   \n",
       "GAACATCTCTGCTGTC-1     0.0    2.0   0.0    0.0     2.0     0.0   0.0   0.0   \n",
       "...                    ...    ...   ...    ...     ...     ...   ...   ...   \n",
       "CGTCAGGGTTTGACAC-1     0.0    0.0   0.0    0.0     0.0     0.0   0.0   0.0   \n",
       "ACGGGTCTCGAACTGT-1     0.0    0.0   0.0    0.0     0.0     0.0   0.0   0.0   \n",
       "GCTGCTTCACCAACCG-1     0.0    0.0   0.0    0.0     0.0     0.0   0.0   0.0   \n",
       "TGGTTCCGTTGATTCG-1     0.0    1.0   0.0    0.0     0.0     0.0   0.0   0.0   \n",
       "CTGCGGACACGAAGCA-1     0.0    0.0   0.0    0.0     0.0     0.0   0.0   0.0   \n",
       "\n",
       "                   B3gnt7 Dpy19l1  ... Chpf2 Mgat4d Bcap31 Pomt2 St8sia2   \n",
       "TACAGTGGTTCAACCA-1    0.0     0.0  ...   0.0    0.0    1.0   0.0     0.0  \\\n",
       "ACATACGAGTGCCATT-1    0.0     0.0  ...   0.0    0.0    0.0   0.0     0.0   \n",
       "TGTCCCATCGGCTTGG-1    0.0     0.0  ...   0.0    0.0    1.0   0.0     0.0   \n",
       "ACTGTCCAGGATGGTC-1    0.0     0.0  ...   0.0    0.0    1.0   0.0     0.0   \n",
       "GAACATCTCTGCTGTC-1    0.0     0.0  ...   0.0    0.0    7.0   0.0     0.0   \n",
       "...                   ...     ...  ...   ...    ...    ...   ...     ...   \n",
       "CGTCAGGGTTTGACAC-1    0.0     0.0  ...   0.0    0.0    0.0   0.0     0.0   \n",
       "ACGGGTCTCGAACTGT-1    0.0     0.0  ...   0.0    0.0    1.0   0.0     0.0   \n",
       "GCTGCTTCACCAACCG-1    0.0     0.0  ...   0.0    0.0    0.0   0.0     0.0   \n",
       "TGGTTCCGTTGATTCG-1    0.0     0.0  ...   0.0    0.0    0.0   0.0     0.0   \n",
       "CTGCGGACACGAAGCA-1    0.0     0.0  ...   0.0    0.0    0.0   0.0     0.0   \n",
       "\n",
       "                   Alg10b Piga Biotin                Type PHA-L  \n",
       "TACAGTGGTTCAACCA-1    0.0  0.0  37384       CD8_NaiveLike   1.0  \n",
       "ACATACGAGTGCCATT-1    0.0  0.0  33249  CD8_EffectorMemory   1.0  \n",
       "TGTCCCATCGGCTTGG-1    0.0  0.0  32029                 Th1   1.0  \n",
       "ACTGTCCAGGATGGTC-1    0.0  0.0  31700      CD8_EarlyActiv   1.0  \n",
       "GAACATCTCTGCTGTC-1    0.0  0.0  31402                Treg   1.0  \n",
       "...                   ...  ...    ...                 ...   ...  \n",
       "CGTCAGGGTTTGACAC-1    0.0  0.0     15       CD8_NaiveLike   0.0  \n",
       "ACGGGTCTCGAACTGT-1    0.0  0.0     13  CD8_EffectorMemory   0.0  \n",
       "GCTGCTTCACCAACCG-1    0.0  0.0     11       CD8_NaiveLike   0.0  \n",
       "TGGTTCCGTTGATTCG-1    0.0  0.0     11       CD8_NaiveLike   0.0  \n",
       "CTGCGGACACGAAGCA-1    0.0  0.0      4       CD8_NaiveLike   0.0  \n",
       "\n",
       "[9824 rows x 244 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glycoTIL_df = glycoTIL.transpose()\n",
    "glycoLN_df = glycoLN.transpose()\n",
    "glycoTIL_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c6782e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "These dataframes are glycoscored and normalized on full, \n",
    "then filtered to only include glycogenes\n",
    "\n",
    "they have genes+biotin+type+score in columns and cells in rows\n",
    "'''\n",
    "\n",
    "with open('glycoTIL_df.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoTIL_df, f)\n",
    "    \n",
    "with open('glycoLN_df.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoLN_df, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27290cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Couldn't find all the genes from glycogene list in dataset, see if we're missing any homologs etc...\n",
    "THe same glycogenes that weren't found in TILs were also not found in LN\n",
    "'''\n",
    "TILnot = [i for i in mouse_glycogenes not in glycoTIL_df.index]\n",
    "TILnot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212bf070",
   "metadata": {},
   "source": [
    "# 7. Split normalized df  into T-cell subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec83ea0",
   "metadata": {},
   "source": [
    "SPLIT data from normLN_full and normLN_full dataframes (pre-glyco score, post full normalization, not glycofiltered) \n",
    "by t-cell subtype\n",
    "store the dataframes into dictionary with t-cell type name as the key \n",
    "\n",
    "normTIL_full and normLN_full have genes + type + biotin in rows and cells in columns\n",
    "\n",
    "Need normalized, glycogene filtered, but not scored dataframes \n",
    "glycoscores affected by number of cells\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9460cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GLycogene filtering on non-scored, normalized df\n",
    "normTIL_full and normLN_full have genes, biotin, type in columns and genes in rows\n",
    "'''\n",
    "# pickle_in = open(\"normTIL_full.pkl\",\"rb\")\n",
    "# normTIL_full = pickle.load(pickle_in)\n",
    "pickle_in = open(\"normTIL_full.pkl\",\"rb\")\n",
    "normTIL_full = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"normLN_full.pkl\",\"rb\")\n",
    "normLN_full = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee62891",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIL = normTIL_full.transpose()\n",
    "LN = normLN_full.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59cab7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of glycogenes looked for: 245\n",
      "Number of glycogenes found in TILs: 241\n",
      "Number of glycogenes found in LNs: 241\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "filter the original matrix by the mouse glycogenes but keep biotin and type info\n",
    "\n",
    "NOTE: input dataframe must have genes in rows and cells in columns\n",
    "'''\n",
    "print('Total number of glycogenes looked for:', len(mouse_glycogenes))\n",
    "\n",
    "\n",
    "#TIL\n",
    "TILglycogenes_found = [i for i in mouse_glycogenes if i in TIL.index]\n",
    "TILglycogenes_notfound = [i for i in mouse_glycogenes if i not in TIL.index]\n",
    "\n",
    "#filter by glycogenes while keeping type&biotin\n",
    "glycoTIL_df = TIL.loc[TILglycogenes_found + ['Biotin', 'Type']] \n",
    "print('Number of glycogenes found in TILs:', len(glycoTIL_df)-2) #-2 accounts for extra type and biotin rows\n",
    "\n",
    "\n",
    "#LN\n",
    "LNglycogenes_found = [i for i in mouse_glycogenes if i in LN.index]\n",
    "LNglycogenes_notfound = [i for i in mouse_glycogenes if i not in LN.index]\n",
    "#filter by glycogenes while keeping type&biotin\n",
    "glycoLN_df = LN.loc[LNglycogenes_found + ['Biotin', 'Type']]\n",
    "print('Number of glycogenes found in LNs:', len(glycoLN_df) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27b00446",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TIL and LN needs to have genes in columns and cells in row to split by T-cell subtype\n",
    "'''\n",
    "#transpose back to get cells in row and genes in column\n",
    "TIL = glycoTIL_df.transpose()\n",
    "LN = glycoLN_df.transpose()\n",
    "\n",
    "# Get list of T-cell subtypes for which to make a dataframe for TILs\n",
    "tcell_subtypes = TIL['Type'].unique()\n",
    "\n",
    "#make dataframe names for later access\n",
    "df_names = [i+'_df' for i in list(tcell_subtypes)]\n",
    "\n",
    "# Make copy of original df just in case\n",
    "splitTIL = TIL.copy()\n",
    "splitLN = LN.copy()\n",
    "\n",
    "\n",
    "TILnorm_dfs_sub = {}\n",
    "LNnorm_dfs_sub = {}\n",
    "\n",
    "# Make separate dataframe containing data for each t-cell subtype\n",
    "for cell_type, name in zip(tcell_subtypes, df_names):\n",
    "    TILnorm_dfs_sub[name] = splitTIL[splitTIL['Type'] == cell_type]\n",
    "    LNnorm_dfs_sub[name] = splitLN[splitLN['Type'] == cell_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e89e66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save pickle of dictionary containing df for each subtype that is normalized but NOT glycoscored \n",
    "# with open('TILnorm_dfs_sub.pkl', 'wb') as f:\n",
    "#     pickle.dump(TILnorm_dfs_sub, f)\n",
    "\n",
    "# with open('LNnorm_dfs_sub.pkl', 'wb') as f:\n",
    "#     pickle.dump(LNnorm_dfs_sub, f)\n",
    "\n",
    "# # f.close()\n",
    "\n",
    "'''load dictionary containing dataframes of non-normalized glycogene dataframes of just T-cells'''\n",
    "pickle_in = open(\"TILnorm_dfs_sub.pkl\",\"rb\")\n",
    "TILtcell_dfs_sub = pickle.load(pickle_in)\n",
    "pickle_in = open( \"LNnorm_dfs_sub.pkl\",\"rb\")\n",
    "LNtcell_dfs_sub = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4343a43",
   "metadata": {},
   "source": [
    "## 7B. Add glycoscores to each subtype df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03deca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off for PHA-L high: 1426; Cut-off for PHA-L low: 519\n",
      "Cut-off for PHA-L high: 2011; Cut-off for PHA-L low: 579\n",
      "Cut-off for PHA-L high: 416; Cut-off for PHA-L low: 187\n",
      "Cut-off for PHA-L high: 330; Cut-off for PHA-L low: 121\n",
      "Cut-off for PHA-L high: 506; Cut-off for PHA-L low: 233\n",
      "Cut-off for PHA-L high: 349; Cut-off for PHA-L low: 150\n",
      "Cut-off for PHA-L high: 403; Cut-off for PHA-L low: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off for PHA-L high: 253; Cut-off for PHA-L low: 126\n",
      "Cut-off for PHA-L high: 1240; Cut-off for PHA-L low: 465\n",
      "Cut-off for PHA-L high: 1691; Cut-off for PHA-L low: 624\n",
      "Cut-off for PHA-L high: 648; Cut-off for PHA-L low: 231\n",
      "Cut-off for PHA-L high: 400; Cut-off for PHA-L low: 133\n",
      "Cut-off for PHA-L high: 873; Cut-off for PHA-L low: 297\n",
      "Cut-off for PHA-L high: 937; Cut-off for PHA-L low: 343\n",
      "Cut-off for PHA-L high: 325; Cut-off for PHA-L low: 162\n",
      "Cut-off for PHA-L high: 182; Cut-off for PHA-L low: 105\n",
      "Cut-off for PHA-L high: 500; Cut-off for PHA-L low: 215\n",
      "Cut-off for PHA-L high: 379; Cut-off for PHA-L low: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/tmp/ipykernel_2923/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n"
     ]
    }
   ],
   "source": [
    "TILglyconorm_sub_df = {}\n",
    "LNglyconorm_sub_df = {}\n",
    "\n",
    "# Make separate dataframe containing data for each t-cell subtype\n",
    "for name in df_names:\n",
    "    TILscored = glycoscore(TILtcell_dfs_sub[name])\n",
    "    TILglyconorm_sub_df[name] = TILscored\n",
    "    LNscored = glycoscore(LNtcell_dfs_sub[name])\n",
    "    LNglyconorm_sub_df[name] = LNscored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49e93081",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save pickle of dictionary containing dataframe for each t-cell subtype normalized and glycoscored\n",
    "- with genes in cols, cells in rows\n",
    "'''\n",
    "with open('TILglyconorm_sub_df.pkl', 'wb') as f:\n",
    "    pickle.dump(TILglyconorm_sub_df, f)\n",
    "\n",
    "with open('LNglyconorm_sub_df.pkl', 'wb') as f:\n",
    "    pickle.dump(LNglyconorm_sub_df, f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# '''load dictionary containing dataframes of non-normalized glycogene dataframes of just T-cells'''\n",
    "# pickle_in = open(pickle_path + \"TILglyconorm_sub_df.pkl\",\"rb\")\n",
    "# TILglyconorm_sub_df = pickle.load(pickle_in)\n",
    "# pickle_in = open(pickle_path + \"LNglyconorm_sub_df.pkl\",\"rb\")\n",
    "# LNglyconorm_sub_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b8f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"TILglyconorm_sub_df.pkl\",\"rb\")\n",
    "TILglyconorm_sub_df = pickle.load(pickle_in)\n",
    "pickle_in = open(\"LNglyconorm_sub_df.pkl\",\"rb\")\n",
    "LNglyconorm_sub_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc83613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtype_comp= pd.read_csv('subtype & cross model testing.csv')\n",
    "sub = subtype_comp[['Data', 'Dimensions']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
