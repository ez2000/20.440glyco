{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2143c82d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as plt\n",
    "import csv\n",
    "import pickle #to save notebook at sessions\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "#set path for pickles to be saved in\n",
    "pickle_path = '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/python pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb1e31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.4\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068cec0",
   "metadata": {},
   "source": [
    "# What is going on (on raw counts)\n",
    "1. Import glycogene csv of human glycogenes converted to mice homologs (because our data is from mice tumor models. Human glycogenes are from glyco.me (Glycopacity). \n",
    "2. Load barcodes, features, and matrix of LN and TILs and convert to dataframe\n",
    "3. Import transformed identity csv with info on which cells are associated with which cell type\n",
    "4. Filter cells from original dataframe to produce smaller dataframe of just TILs in LN/TIL population from transformed identity csv\n",
    "5. Filter genes from filtered dataframe (from 4) to only include glycogenes from (1)\n",
    "6. Convert filtered dataframe back into a sparse matrix for export into .mtx file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac3d0e",
   "metadata": {},
   "source": [
    "## 1. Import human to mouse glycogene csv.\n",
    "Converted human glycogenes to their mouse homologs via https://www.informatics.jax.org/batch/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a61d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load mouse glycogenes \n",
    "\n",
    "glyco_fp = '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/human to mouse glycogene converted.csv'\n",
    "glycogene_df = pd.read_csv(glyco_fp)\n",
    "\n",
    "#make mouse glycogene list\n",
    "m_glyco = glycogene_df[['Mouse']]\n",
    "mouse_glyco_long = list(m_glyco.dropna(axis=0)['Mouse']) #removed 3 genes that didn't have mice homologs\n",
    "\n",
    "#export just the mouse glycogenes as csv\n",
    "m_glyco.to_csv('Mouse glycogenes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c037a8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicates\n",
    "mouse_glycogenes = set(mouse_glyco_long)\n",
    "len(mouse_glyco_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d246c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mouse_glycogenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90fdba",
   "metadata": {},
   "source": [
    "## 2. Load barcodes, features, and matrix of LN and TILs and convert to dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd05562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TAKES LONG TIME TO RUN!! ## \n",
    "# Load the LN SUGAR-seq matrix from file\n",
    "sparse_LN = sp.io.mmread(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/matrix.mtx')\n",
    "# Convert to CSR format\n",
    "sparse_LN = sp.sparse.csr_matrix(sparse_LN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c2b8b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_72324/477600803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## TAKES LONG TIME TO RUN!! ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load the TIL SUGAR-seq matrix from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m sparse_TIL = sp.io.mmread(\n\u001b[0m\u001b[1;32m      4\u001b[0m     '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx')\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Convert to CSR format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/io/_mmio.py\u001b[0m in \u001b[0;36mmmread\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMMFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/io/_mmio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/io/_mmio.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(filespec, mode)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilespec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilespec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# open for writing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx'"
     ]
    }
   ],
   "source": [
    "## TAKES LONG TIME TO RUN!! ## \n",
    "# Load the TIL SUGAR-seq matrix from file\n",
    "sparse_TIL = sp.io.mmread(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/matrix.mtx')\n",
    "# Convert to CSR format\n",
    "sparse_TIL = sp.sparse.csr_matrix(sparse_TIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension check of sparse matrix\n",
    "print('LN matrix dimesions are', np.shape(sparse_LN)) #31059 = rows , 21343=columns\n",
    "print('TIL matrix dimesions are', np.shape(sparse_TIL))\n",
    "\n",
    "# convert sparse matrices to array to put into dataframe\n",
    "LN_matrix = sparse_LN.toarray()\n",
    "TIL_matrix = sparse_TIL.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d82de",
   "metadata": {},
   "source": [
    "### Set up data frame for TIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807dfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TIL data ##  \n",
    "# barcodes = row names\n",
    "barcodes = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/barcodes copy.tsv', \n",
    "    header=None)\n",
    "barcodes = barcodes.rename(columns={0: 'barcode'})\n",
    "TIL_barcodes = list(barcodes['barcode']) # of columns =  21343\n",
    "\n",
    "# features = column names\n",
    "feats = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/features.tsv', \n",
    "    header = None)\n",
    "with open('/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/TIL data/features.tsv', \n",
    "          'r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    feat_ls = []\n",
    "    for row in reader:\n",
    "        feat_ls.append(row)\n",
    "TIL_features = [i[1] for i in feat_ls] # of rows = 31059\n",
    "\n",
    "# Convert the dense matrix to a pandas DataFrame\n",
    "TIL_df = pd.DataFrame(data=TIL_matrix, index=TIL_features, columns=TIL_barcodes)\n",
    "\n",
    "# Remove rows for HTO1, HTO2, PD1, and TIM3 (ADT and HTO assays)\n",
    "TIL_df_new = TIL_df.drop(['HTO1', 'HTO2','PD1', 'TIM3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f68f99",
   "metadata": {},
   "source": [
    "### set up dataframe for LN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a23ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LN data ## \n",
    "# barcodes = row names\n",
    "barcodes = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/barcodes copy.tsv', \n",
    "    header=None)\n",
    "barcodes = barcodes.rename(columns={0: 'barcode'})\n",
    "LN_barcodes = list(barcodes['barcode']) # of columns =  21343\n",
    "\n",
    "# features = column names\n",
    "feats = pd.read_csv(\n",
    "    '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/features.tsv', header = None)\n",
    "with open('/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/raw data/LN data/features.tsv', \n",
    "          'r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    feat_ls = []\n",
    "    for row in reader:\n",
    "        feat_ls.append(row)\n",
    "LN_features = [i[1] for i in feat_ls] # of rows = 31059\n",
    "\n",
    "# Convert the dense matrix to a pandas DataFrame with columns as each barcode and rows as each gene\n",
    "LN_df = pd.DataFrame(data=LN_matrix, index=LN_features, columns=LN_barcodes)\n",
    "\n",
    "# Remove rows for HTO1, HTO2, PD1, and TIM3 (ADT and HTO assays)\n",
    "LN_df_new = LN_df.drop(['hashtag1', 'hashtag2','hashtag3', 'PD1_hash', 'TIM3_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL df set up.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_df_new, f)\n",
    "    \n",
    "with open(pickle_path + 'LN df set up.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_df_new, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f52bf",
   "metadata": {},
   "source": [
    "## 3. Add cell type info from csv exported from ProjecTIL cell type annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa85488",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL df set up.pkl', 'rb') as f:\n",
    "    TIL_df_new = pickle.load(f)\n",
    "\n",
    "with open(pickle_path + 'LN df set up.pkl', 'rb') as f:\n",
    "    LN_df_new = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c9a133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#check to see St6galnac2 -->  non-identical columns but named the same \n",
    "n = TIL_df_new.transpose()\n",
    "n = n.filter(regex='^St6galnac2$')\n",
    "names = ['1','2']\n",
    "n.columns = names\n",
    "n\n",
    "print(n['1'].equals(n['2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdbfeec",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/TIL output/ProjecTIL analysis/TIL_transformed_identity.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_17060/1230910064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# import ProjecTIL analysis output to add cell type annotation to raw glycogene data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mTIL_transformed_ident\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_TIL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mLN_transformed_ident\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_LN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/TIL output/ProjecTIL analysis/TIL_transformed_identity.csv'"
     ]
    }
   ],
   "source": [
    "path_TIL='/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/TIL output/ProjecTIL analysis/TIL_transformed_identity.csv'\n",
    "path_LN='/Users/erikazhang/Dropbox (MIT)/20.440 Biological Networks/project/LN output/ProjecTIL analysis/LN_transformed_identity.csv'\n",
    "\n",
    "# import ProjecTIL analysis output to add cell type annotation to raw glycogene data frame \n",
    "TIL_transformed_ident = pd.read_csv(path_TIL)\n",
    "LN_transformed_ident = pd.read_csv(path_LN)\n",
    "\n",
    "#rename column of ProjecTIL df for easy identification of barcodes\n",
    "TIL_transformed_ident = TIL_transformed_ident.rename(columns={'Unnamed: 0':'Barcodes'}) \n",
    "LN_transformed_ident = LN_transformed_ident.rename(columns={'Unnamed: 0':'Barcodes'}) \n",
    "\n",
    "#Transpose matrix to match final TIL/LN matrix format\n",
    "TIL_transformed_ident = TIL_transformed_ident.transpose()\n",
    "LN_transformed_ident = LN_transformed_ident.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1dd9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUn only once, else it keeps replacing index with top row. if you run too much, rerun previous cell first!! \n",
    "'''\n",
    "make the column names the barcodes, which is how the glycogene \n",
    "dataframe (the one we want to combine this one with) is formatted as, to concatenate\n",
    "'''\n",
    "TIL_transformed_ident.set_axis(TIL_transformed_ident.iloc[0], axis=1, inplace=True)\n",
    "TIL_transformed_ident = TIL_transformed_ident[1:] \n",
    "\n",
    "LN_transformed_ident.set_axis(LN_transformed_ident.iloc[0], axis=1, inplace=True)\n",
    "LN_transformed_ident = LN_transformed_ident[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as binarized pickle file \n",
    "with open(pickle_path + 'TIL_transformed_ident.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_transformed_ident, f)\n",
    "    \n",
    "with open(pickle_path + 'LN_transformed_ident.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_transformed_ident, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5e874",
   "metadata": {},
   "source": [
    "### Remove non-TILs from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5049fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe dimensions are  (31054, 19912) and the filtered dataframe dimensions are (31054, 19645)\n",
      "Original dataframe dimensions are  (31054, 21343) and the filtered dataframe dimensions are (31054, 21296)\n"
     ]
    }
   ],
   "source": [
    "# # filter original matrix by barcodes of cells identified as TILs via ProjecTILs #\n",
    "\n",
    "# extract list of barcodes that have a T-cell annotation\n",
    "TIL_barcodes = list(TIL_transformed_ident.columns)\n",
    "LN_barcodes = list(LN_transformed_ident.columns)\n",
    "\n",
    "\n",
    "filtered_TIL_df = TIL_df_new[TIL_barcodes]\n",
    "filtered_LN_df = LN_df_new[LN_barcodes]\n",
    "\n",
    "print('Original dataframe dimensions are ', TIL_df_new.shape, \n",
    "      'and the filtered dataframe dimensions are', filtered_TIL_df.shape)\n",
    "print('Original dataframe dimensions are ', LN_df_new.shape, \n",
    "      'and the filtered dataframe dimensions are', filtered_LN_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as binarized pickle file \n",
    "with open(pickle_path + 'filtered_TIL_df.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_TIL_df, f)\n",
    "    \n",
    "with open(pickle_path + 'filtered_LN_df.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_LN_df, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97ec8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##TAKES LONG TIME TO RUN##\n",
    "'''\n",
    "Add cell type information via concatenation\n",
    "Note: the L-Pha information from this csv is normalized, and since we're using raw data we'll use the raw biotin info\n",
    "'''\n",
    "TIL_type = TIL_transformed_ident.loc[['Type']]\n",
    "LN_type = LN_transformed_ident.loc[['Type']]\n",
    "\n",
    "#makes new dataframe that adds T-cell type annotations to raw gene expression dataframe \n",
    "TIL_type_df = pd.concat([filtered_TIL_df, TIL_type])\n",
    "LN_type_df = pd.concat([filtered_LN_df, LN_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd39b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL_type_df.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_type_df, f)\n",
    "    \n",
    "with open(pickle_path + 'LN_type_df.pkl', 'wb') as f:\n",
    "    pickle.dump(LN_type_df, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fdf5e2",
   "metadata": {},
   "source": [
    "## 4. DO normalization and glycoscoring of T-cells via full transcriptome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489f0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'TIL_type_df.pkl', 'rb') as f:\n",
    "    TIL_type_df = pickle.load(f)\n",
    "\n",
    "with open(pickle_path + 'LN_type_df.pkl', 'rb') as f:\n",
    "    LN_type_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34df235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAACCTGAGATGGCGT-1</th>\n",
       "      <th>AAACCTGAGCGAGAAA-1</th>\n",
       "      <th>AAACCTGAGCTGGAAC-1</th>\n",
       "      <th>AAACCTGAGGATTCGG-1</th>\n",
       "      <th>AAACCTGAGTCTCAAC-1</th>\n",
       "      <th>AAACCTGCAAATACAG-1</th>\n",
       "      <th>AAACCTGCAAGCCCAC-1</th>\n",
       "      <th>AAACCTGCAATAGAGT-1</th>\n",
       "      <th>AAACCTGCAGATCCAT-1</th>\n",
       "      <th>AAACCTGCAGATGGGT-1</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTGTCATCAACACGT-1</th>\n",
       "      <th>TTTGTCATCAAGGTAA-1</th>\n",
       "      <th>TTTGTCATCAGAAATG-1</th>\n",
       "      <th>TTTGTCATCAGGCAAG-1</th>\n",
       "      <th>TTTGTCATCAGTGTTG-1</th>\n",
       "      <th>TTTGTCATCATGTCTT-1</th>\n",
       "      <th>TTTGTCATCCAATGGT-1</th>\n",
       "      <th>TTTGTCATCGGATGGA-1</th>\n",
       "      <th>TTTGTCATCTACTTAC-1</th>\n",
       "      <th>TTTGTCATCTAGCACA-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Xkr4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gm1992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gm37381</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rp1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sox17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAAA01118383.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vmn2r122</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAAA01147332.1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biotin</th>\n",
       "      <td>1052</td>\n",
       "      <td>799</td>\n",
       "      <td>231</td>\n",
       "      <td>507</td>\n",
       "      <td>197</td>\n",
       "      <td>440</td>\n",
       "      <td>2265</td>\n",
       "      <td>227</td>\n",
       "      <td>221</td>\n",
       "      <td>1014</td>\n",
       "      <td>...</td>\n",
       "      <td>1185</td>\n",
       "      <td>1078</td>\n",
       "      <td>329</td>\n",
       "      <td>260</td>\n",
       "      <td>204</td>\n",
       "      <td>221</td>\n",
       "      <td>173</td>\n",
       "      <td>247</td>\n",
       "      <td>174</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>Treg</td>\n",
       "      <td>Th1</td>\n",
       "      <td>Treg</td>\n",
       "      <td>Th1</td>\n",
       "      <td>CD8_EarlyActiv</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_Tex</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>Treg</td>\n",
       "      <td>...</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "      <td>Treg</td>\n",
       "      <td>CD8_Tex</td>\n",
       "      <td>Th1</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "      <td>Th1</td>\n",
       "      <td>Treg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31055 rows × 19645 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AAACCTGAGATGGCGT-1 AAACCTGAGCGAGAAA-1 AAACCTGAGCTGGAAC-1  \\\n",
       "Xkr4                            0                  0                  0   \n",
       "Gm1992                          0                  0                  0   \n",
       "Gm37381                         0                  0                  0   \n",
       "Rp1                             0                  0                  0   \n",
       "Sox17                           0                  0                  0   \n",
       "...                           ...                ...                ...   \n",
       "CAAA01118383.1                  0                  0                  0   \n",
       "Vmn2r122                        0                  0                  0   \n",
       "CAAA01147332.1                  1                  1                  0   \n",
       "Biotin                       1052                799                231   \n",
       "Type                         Treg                Th1               Treg   \n",
       "\n",
       "               AAACCTGAGGATTCGG-1 AAACCTGAGTCTCAAC-1 AAACCTGCAAATACAG-1  \\\n",
       "Xkr4                            0                  0                  0   \n",
       "Gm1992                          0                  0                  0   \n",
       "Gm37381                         0                  0                  0   \n",
       "Rp1                             0                  0                  0   \n",
       "Sox17                           0                  0                  0   \n",
       "...                           ...                ...                ...   \n",
       "CAAA01118383.1                  0                  0                  0   \n",
       "Vmn2r122                        0                  0                  0   \n",
       "CAAA01147332.1                  0                  0                  3   \n",
       "Biotin                        507                197                440   \n",
       "Type                          Th1     CD8_EarlyActiv      CD8_NaiveLike   \n",
       "\n",
       "               AAACCTGCAAGCCCAC-1  AAACCTGCAATAGAGT-1 AAACCTGCAGATCCAT-1  \\\n",
       "Xkr4                            0                   0                  0   \n",
       "Gm1992                          0                   0                  0   \n",
       "Gm37381                         0                   0                  0   \n",
       "Rp1                             0                   0                  0   \n",
       "Sox17                           0                   0                  0   \n",
       "...                           ...                 ...                ...   \n",
       "CAAA01118383.1                  1                   1                  0   \n",
       "Vmn2r122                        0                   0                  0   \n",
       "CAAA01147332.1                  4                   0                  0   \n",
       "Biotin                       2265                 227                221   \n",
       "Type                      CD8_Tex  CD8_EffectorMemory      CD8_NaiveLike   \n",
       "\n",
       "               AAACCTGCAGATGGGT-1  ...  TTTGTCATCAACACGT-1 TTTGTCATCAAGGTAA-1  \\\n",
       "Xkr4                            0  ...                   0                  0   \n",
       "Gm1992                          0  ...                   0                  0   \n",
       "Gm37381                         0  ...                   0                  0   \n",
       "Rp1                             0  ...                   0                  0   \n",
       "Sox17                           0  ...                   0                  0   \n",
       "...                           ...  ...                 ...                ...   \n",
       "CAAA01118383.1                  1  ...                   0                  0   \n",
       "Vmn2r122                        0  ...                   0                  0   \n",
       "CAAA01147332.1                  0  ...                   0                  2   \n",
       "Biotin                       1014  ...                1185               1078   \n",
       "Type                         Treg  ...  CD8_EffectorMemory               Treg   \n",
       "\n",
       "               TTTGTCATCAGAAATG-1 TTTGTCATCAGGCAAG-1 TTTGTCATCAGTGTTG-1  \\\n",
       "Xkr4                            0                  0                  0   \n",
       "Gm1992                          0                  0                  0   \n",
       "Gm37381                         0                  0                  0   \n",
       "Rp1                             0                  0                  0   \n",
       "Sox17                           0                  0                  0   \n",
       "...                           ...                ...                ...   \n",
       "CAAA01118383.1                  0                  0                  0   \n",
       "Vmn2r122                        0                  0                  0   \n",
       "CAAA01147332.1                  2                  0                  0   \n",
       "Biotin                        329                260                204   \n",
       "Type                      CD8_Tex                Th1      CD8_NaiveLike   \n",
       "\n",
       "                TTTGTCATCATGTCTT-1  TTTGTCATCCAATGGT-1 TTTGTCATCGGATGGA-1  \\\n",
       "Xkr4                             0                   0                  0   \n",
       "Gm1992                           0                   0                  0   \n",
       "Gm37381                          0                   0                  0   \n",
       "Rp1                              0                   0                  0   \n",
       "Sox17                            0                   0                  0   \n",
       "...                            ...                 ...                ...   \n",
       "CAAA01118383.1                   2                   0                  0   \n",
       "Vmn2r122                         0                   0                  0   \n",
       "CAAA01147332.1                   0                   0                  0   \n",
       "Biotin                         221                 173                247   \n",
       "Type            CD8_EffectorMemory  CD8_EffectorMemory      CD8_NaiveLike   \n",
       "\n",
       "               TTTGTCATCTACTTAC-1 TTTGTCATCTAGCACA-1  \n",
       "Xkr4                            0                  0  \n",
       "Gm1992                          0                  0  \n",
       "Gm37381                         0                  0  \n",
       "Rp1                             0                  0  \n",
       "Sox17                           0                  0  \n",
       "...                           ...                ...  \n",
       "CAAA01118383.1                  0                  0  \n",
       "Vmn2r122                        0                  0  \n",
       "CAAA01147332.1                  1                  0  \n",
       "Biotin                        174                361  \n",
       "Type                          Th1               Treg  \n",
       "\n",
       "[31055 rows x 19645 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIL_type_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abebdff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy = TIL_type_df[:-2]\n",
    "cols_to_standardize = toy.columns\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f0db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_40313/1195105872.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  col1[std]=scaler.fit_transform(col1[std])\n"
     ]
    }
   ],
   "source": [
    "col1 = toy[1:]\n",
    "col1\n",
    "std = col1.columns\n",
    "col1[std]=scaler.fit_transform(col1[std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772946d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy[cols_to_standardize] = scaler.fit_transform(toy[cols_to_standardize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a99f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of columns in each part\n",
    "num_cols = toy.shape[1]\n",
    "cols_per_part = int(np.ceil(num_cols / 4))\n",
    "\n",
    "# select the columns for each part\n",
    "part1 = toy.iloc[:, :cols_per_part]\n",
    "part2 = toy.iloc[:, cols_per_part:2*cols_per_part]\n",
    "part3 = toy.iloc[:, 2*cols_per_part:3*cols_per_part]\n",
    "part4 = toy.iloc[:, 3*cols_per_part:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa124934",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_to_append = TIL_type_df.iloc[-2:]\n",
    "\n",
    "norm_df = pd.concat([toy_df, scores_to_append])\n",
    "norm_df = norm_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf9ada89",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Perform robust scaler normalization\n",
    "\n",
    "This defines a function that normalizes expression across the different genes for each cell.\n",
    "\n",
    "input:\n",
    "- df with last 2 rows that are type, biotin\n",
    "- rows = genes, columns = cells\n",
    "\n",
    "output:\n",
    "- scaled df with same dimensions\n",
    "- df with columns as genes and rows as cells\n",
    "'''\n",
    "\n",
    "def robust_normalization(df):\n",
    "    ## isolate just gene columns and standardize \n",
    "    toy_df = df.iloc[:-2]\n",
    "    cols_to_standardize = toy_df.columns\n",
    "    scaler = RobustScaler()\n",
    "    toy_df[cols_to_standardize] = scaler.fit_transform(toy_df[cols_to_standardize])\n",
    "    \n",
    "    ## extract biotin, t-cell type, and L-PHA data from original dataframe and append to transformed data\n",
    "    scores_to_append = df.iloc[-2:]\n",
    "\n",
    "    norm_df = pd.concat([toy_df, scores_to_append])\n",
    "    norm_df = norm_df.transpose()\n",
    "   \n",
    "    return norm_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d87d097",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now want to add Glycosylation (PHA-L) column that assigns:\n",
    "Yes (1) to top 25%, \n",
    "No (0) to bottom 25%\n",
    "\n",
    "categorize_lectin \n",
    "inputs:\n",
    "- data_all: a dataframe that has\n",
    "    - genes in the columns headers\n",
    "    - barcodes as row indices\n",
    "    - a column with biotin values to use as cutoffs for top 25% and bottom 25%\n",
    "- quantile_high: upper quantile threshold (75% to represent top 25% of data below which 75% of the data falls)\n",
    "- quantile_low: lower quantile threshold (25% to represent bottom 25% of data below which 25% of data falls)\n",
    "- ref_col_loc: index of column in data_all that is used for categorization cutoffs\n",
    "\n",
    "outputs:\n",
    "- cutoff values for high and low biotin\n",
    "- list of 3 arrays representing indices of rows that meet the high biotin cutoff, \n",
    "low biotin cutoff, and combined high and low cutoff\n",
    "- number of rows that meet the high category cutoff and the low category cutoff.\n",
    "'''\n",
    "\n",
    "# Function: determine PHA-L read cut-offs for binary classification FROM BOJAR LAB\n",
    "def categorize_lectin(data_all, quantile_high, quantile_low, ref_col_loc):\n",
    "    cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
    "\n",
    "    print(f\"Cut-off for PHA-L high: {cutoff[0]}; Cut-off for PHA-L low: {cutoff[1]}\")\n",
    "\n",
    "    high_indices = np.array(data_all.loc[:,ref_col_loc]>=cutoff[0])\n",
    "    low_indices = np.array(data_all.loc[:,ref_col_loc]<cutoff[1])\n",
    "    high_low_indices = np.logical_or(high_indices, low_indices)\n",
    "\n",
    "    high_count = high_indices.sum()\n",
    "    low_count = low_indices.sum()\n",
    "\n",
    "    return cutoff, [high_indices, low_indices, high_low_indices], [high_count, low_count]\n",
    "\n",
    "\n",
    "'''\n",
    "Function assigns binary glycoscore to input df\n",
    "\n",
    "input:\n",
    "- c = dataframe containing normalized counts of gene expression per cell\n",
    "- Need last 2 columns to be 'Type' and 'Biotin' col\n",
    "- genes on column, cell barcodes on row \n",
    "\n",
    "output:\n",
    "- dataframe containing new column for L-PHA score \n",
    "- genes on column, barcodes on row \n",
    "'''\n",
    "\n",
    "def glycoscore(c):\n",
    "    #sort dataframe by 'Biotin values'\n",
    "    c = c.sort_values(by='Biotin', ascending=False)\n",
    "    # Parameters for categorize lectin function\n",
    "    quantile_high, quantile_low = 0.75, 0.25\n",
    "    ref_col = 'Biotin' #last column of dataframes contain biotin info\n",
    "\n",
    "    #split df into quartiles \n",
    "    cutoff, indices, count = categorize_lectin(c, quantile_high, quantile_low, ref_col)\n",
    "\n",
    "    # Assign 1 to top 25% and 0 to bottom 25%\n",
    "    c.loc[indices[0], \"PHA-L\"] = 1\n",
    "    c.loc[indices[1], \"PHA-L\"] = 0\n",
    "\n",
    "    # Drop the middle two quartiles\n",
    "    c = c.loc[indices[2], :]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c517df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIL = TIL_type_df.copy()\n",
    "LN = LN_type_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2757b2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = TIL.transpose(a)\n",
    "n = n.filter(regex='^St6galnac2$')\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Normalize gene counts across all genes for each T-cell\n",
    "\n",
    "recall robust normalization will spit out TRANSPOSED dataframe\n",
    "TAKES FOREVER\n",
    "'''\n",
    "normTIL = robust_normalization(TIL)\n",
    "normLN = robust_normalization(LN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Biotin_hash column in LN dataframe to 'Biotin' for easy glycoscoring via glycoscore function\n",
    "pre_scoredLN = pre_scoredLN.rename(columns={'Biotin_hash': 'Biotin'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862318b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign glycoscores to each cell\n",
    "TIL_glyconorm = = glycoscore(pre_scoredTIL)\n",
    "LN_glyconorm = glycoscore(pre_scoredLN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b716499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle of df\n",
    "with open(pickle_path + 'full_TIL_glyconorm.pkl', 'wb') as f:\n",
    "    pickle.dump(TIL_glyconorm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0e141",
   "metadata": {},
   "source": [
    "## 5. Filter matrix to only include glycogenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4104a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'full_TIL_glyconorm.pkl', 'rb') as f:\n",
    "    full_TIL_glyconorm = pickle.load(f)\n",
    "\n",
    "with open(pickle_path + 'full_LN_glyconorm.pkl', 'rb') as f:\n",
    "    full_LN_glyconorm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96922652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER the original matrix by the mouse glycogenes but keep biotin and type info\n",
    "print('Total number of glycogenes looked for:', len(mouse_glycogenes))\n",
    "\n",
    "#Look for glycogenes withixn TIL_type_df\n",
    "TILglycogenes_found = [i for i in mouse_glycogenes if i in TIL_type_df.index]\n",
    "TILglycogenes_notfound = [i for i in mouse_glycogenes if i not in TIL_type_df.index]\n",
    "\n",
    "glycoTIL_df = TIL_type_df.loc[TILglycogenes_found + ['Biotin', 'Type']] #filter by glycogenes while keeping type&biotin\n",
    "print('Number of glycogenes found in TILs:', len(glycoTIL_df)-2) #-2 accounts for extra type and biotin rows\n",
    "\n",
    "\n",
    "#Look for glycogenes within LN_type_df\n",
    "LNglycogenes_found = [i for i in mouse_glycogenes if i in LN_type_df.index]\n",
    "LNglycogenes_notfound = [i for i in mouse_glycogenes if i not in LN_type_df.index]\n",
    "\n",
    "glycoLN_df = LN_type_df.loc[LNglycogenes_found + ['Biotin_hash', 'Type']] #filter by glycogenes while keeping type&biotin\n",
    "print('Number of glycogenes found in LNs:', len(glycoLN_df) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "88964461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>St6galnac2</th>\n",
       "      <th>St6galnac2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGATGGCGT-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGCGAGAAA-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGCTGGAAC-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGGATTCGG-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGTCTCAAC-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCATGTCTT-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCCAATGGT-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCGGATGGA-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCTACTTAC-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCTAGCACA-1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19645 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   St6galnac2 St6galnac2\n",
       "AAACCTGAGATGGCGT-1          0          0\n",
       "AAACCTGAGCGAGAAA-1          0          0\n",
       "AAACCTGAGCTGGAAC-1          0          0\n",
       "AAACCTGAGGATTCGG-1          0          0\n",
       "AAACCTGAGTCTCAAC-1          0          0\n",
       "...                       ...        ...\n",
       "TTTGTCATCATGTCTT-1          0          0\n",
       "TTTGTCATCCAATGGT-1          0          0\n",
       "TTTGTCATCGGATGGA-1          0          0\n",
       "TTTGTCATCTACTTAC-1          0          0\n",
       "TTTGTCATCTAGCACA-1          0          0\n",
       "\n",
       "[19645 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n = glycoTIL_df.transpose()\n",
    "# n = n.filter(regex='^St6galnac2$')\n",
    "# n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c6782e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_path + 'glycoTIL_df.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoTIL_df, f)\n",
    "    \n",
    "with open(pickle_path + 'glycoLN_df.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoLN_df, f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27290cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Couldn't find all the genes from glycogene list in dataset, see if we're missing any homologs etc...\n",
    "THe same glycogenes that weren't found in TILs were also not found in LN\n",
    "'''\n",
    "TILnot = [i for i in mouse_glycogenes not in glycoTIL_df.index]\n",
    "TILnot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41025b69",
   "metadata": {},
   "source": [
    "# 6 Assign glycoscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "19ec212c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off for PHA-L high: 738; Cut-off for PHA-L low: 237\n",
      "Cut-off for PHA-L high: 276; Cut-off for PHA-L low: 127\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "RECALL:\n",
    "glycoscore requires genes in columns and cells in rows\n",
    "'''\n",
    "glycoTIL_normscored = glycoscore(glycoTIL_df)\n",
    "glycoLN_normscored = glycoscore(glycoLN_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "212589ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B4galnt2</th>\n",
       "      <th>B4galnt4</th>\n",
       "      <th>Timm44</th>\n",
       "      <th>Dpy19l2</th>\n",
       "      <th>Bcap31</th>\n",
       "      <th>Mgat1</th>\n",
       "      <th>Hs3st4</th>\n",
       "      <th>Galnt3</th>\n",
       "      <th>B3galt2</th>\n",
       "      <th>A4gnt</th>\n",
       "      <th>...</th>\n",
       "      <th>Gcnt1</th>\n",
       "      <th>Mgat4d</th>\n",
       "      <th>Fut1</th>\n",
       "      <th>Alg1</th>\n",
       "      <th>Galnt13</th>\n",
       "      <th>B4galt4</th>\n",
       "      <th>Pdcd6</th>\n",
       "      <th>Mfng</th>\n",
       "      <th>Biotin</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGATGGCGT-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1052</td>\n",
       "      <td>Treg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGCGAGAAA-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>799</td>\n",
       "      <td>Th1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGCTGGAAC-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>231</td>\n",
       "      <td>Treg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGGATTCGG-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>507</td>\n",
       "      <td>Th1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCTGAGTCTCAAC-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197</td>\n",
       "      <td>CD8_EarlyActiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCATGTCTT-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>221</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCCAATGGT-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173</td>\n",
       "      <td>CD8_EffectorMemory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCGGATGGA-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247</td>\n",
       "      <td>CD8_NaiveLike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCTACTTAC-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174</td>\n",
       "      <td>Th1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTCATCTAGCACA-1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>361</td>\n",
       "      <td>Treg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19645 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   B4galnt2 B4galnt4 Timm44 Dpy19l2 Bcap31 Mgat1 Hs3st4  \\\n",
       "AAACCTGAGATGGCGT-1      0.0      0.0    0.0     0.0    0.0   0.0    0.0   \n",
       "AAACCTGAGCGAGAAA-1      0.0      0.0    0.0     0.0    2.0   1.0    0.0   \n",
       "AAACCTGAGCTGGAAC-1      0.0      0.0    0.0     0.0    1.0   1.0    0.0   \n",
       "AAACCTGAGGATTCGG-1      0.0      0.0    0.0     0.0    2.0   0.0    0.0   \n",
       "AAACCTGAGTCTCAAC-1      0.0      0.0    0.0     0.0    0.0   0.0    0.0   \n",
       "...                     ...      ...    ...     ...    ...   ...    ...   \n",
       "TTTGTCATCATGTCTT-1      0.0      1.0    2.0     0.0    3.0   0.0    0.0   \n",
       "TTTGTCATCCAATGGT-1      0.0      0.0    0.0     0.0    1.0   0.0    0.0   \n",
       "TTTGTCATCGGATGGA-1      0.0      0.0    0.0     0.0    0.0   0.0    0.0   \n",
       "TTTGTCATCTACTTAC-1      0.0      0.0    0.0     0.0    1.0   0.0    0.0   \n",
       "TTTGTCATCTAGCACA-1      0.0      0.0    1.0     0.0    0.0   1.0    0.0   \n",
       "\n",
       "                   Galnt3 B3galt2 A4gnt  ... Gcnt1 Mgat4d Fut1 Alg1 Galnt13  \\\n",
       "AAACCTGAGATGGCGT-1    0.0     0.0   0.0  ...   0.0    0.0  0.0  0.0     0.0   \n",
       "AAACCTGAGCGAGAAA-1    0.0     0.0   0.0  ...   0.0    0.0  0.0  0.0     0.0   \n",
       "AAACCTGAGCTGGAAC-1    0.0     0.0   0.0  ...   0.0    0.0  0.0  0.0     0.0   \n",
       "AAACCTGAGGATTCGG-1    0.0     0.0   0.0  ...   0.0    0.0  0.0  1.0     0.0   \n",
       "AAACCTGAGTCTCAAC-1    0.0     0.0   0.0  ...   0.0    0.0  0.0  0.0     0.0   \n",
       "...                   ...     ...   ...  ...   ...    ...  ...  ...     ...   \n",
       "TTTGTCATCATGTCTT-1    1.0     0.0   0.0  ...   0.0    0.0  0.0  0.0     0.0   \n",
       "TTTGTCATCCAATGGT-1    0.0     0.0   0.0  ...   0.0    0.0  0.0  0.0     0.0   \n",
       "TTTGTCATCGGATGGA-1    0.0     0.0   0.0  ...   0.0    0.0  0.0  0.0     0.0   \n",
       "TTTGTCATCTACTTAC-1    0.0     0.0   0.0  ...   1.0    0.0  0.0  0.0     0.0   \n",
       "TTTGTCATCTAGCACA-1    0.0     0.0   0.0  ...   0.0    0.0  0.0  0.0     0.0   \n",
       "\n",
       "                   B4galt4 Pdcd6 Mfng Biotin                Type  \n",
       "AAACCTGAGATGGCGT-1     0.0   1.0  0.0   1052                Treg  \n",
       "AAACCTGAGCGAGAAA-1     0.0   0.0  1.0    799                 Th1  \n",
       "AAACCTGAGCTGGAAC-1     0.0   0.0  0.0    231                Treg  \n",
       "AAACCTGAGGATTCGG-1     0.0   5.0  0.0    507                 Th1  \n",
       "AAACCTGAGTCTCAAC-1     0.0   0.0  0.0    197      CD8_EarlyActiv  \n",
       "...                    ...   ...  ...    ...                 ...  \n",
       "TTTGTCATCATGTCTT-1     0.0   1.0  2.0    221  CD8_EffectorMemory  \n",
       "TTTGTCATCCAATGGT-1     0.0   0.0  0.0    173  CD8_EffectorMemory  \n",
       "TTTGTCATCGGATGGA-1     0.0   0.0  0.0    247       CD8_NaiveLike  \n",
       "TTTGTCATCTACTTAC-1     0.0   0.0  0.0    174                 Th1  \n",
       "TTTGTCATCTAGCACA-1     0.0   1.0  0.0    361                Treg  \n",
       "\n",
       "[19645 rows x 243 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normTIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f52b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle of robust normalized, glycoscored df of just T-cells and 244 glycogenes (housekeeping included)\n",
    "with open(pickle_path + 'glycoTIL_normscored.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoTIL_normscored, f)\n",
    "    \n",
    "with open(pickle_path + 'glycoLN_normscored.pkl', 'wb') as f:\n",
    "    pickle.dump(glycoLN_normscored, f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# # ## load updated df from pickle\n",
    "# pickle_in = open(pickle_path +\"glycoTIL_normscored.pkl\",\"rb\")\n",
    "# glycoTIL_normscored = pickle.load(pickle_in)\n",
    "\n",
    "# pickle_in = open(pickle_path +\"glycoLN_normscored.pkl\",\"rb\")\n",
    "# glycoLN_normscored = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212bf070",
   "metadata": {},
   "source": [
    "# 7. Split normalized df  into T-cell subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "27b00446",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "SPLIT data from normLN and normTIL dataframes by t-cell subtype\n",
    "store the dataframes into dictionary with t-cell type name as the key \n",
    "\n",
    "normLN and normTIL have cells in rows and genes + type + biotin in columns\n",
    "'''\n",
    "\n",
    "# Get list of T-cell subtypes for which to make a dataframe for TILs\n",
    "tcell_subtypes = normTIL['Type'].unique()\n",
    "\n",
    "#make dataframe names for later access\n",
    "df_names = [i+'_df' for i in list(tcell_subtypes)]\n",
    "\n",
    "# Make copy of original df just in case\n",
    "splitTIL = normTIL.copy()\n",
    "splitLN = normLN.copy()\n",
    "\n",
    "\n",
    "TILtcell_dfs_sub = {}\n",
    "LNtcell_dfs_sub = {}\n",
    "\n",
    "# Make separate dataframe containing data for each t-cell subtype\n",
    "for cell_type, name in zip(tcell_subtypes, df_names):\n",
    "    TILtcell_dfs_sub[name] = splitTIL[splitTIL['Type'] == cell_type]\n",
    "    LNtcell_dfs_sub[name] = splitLN[splitLN['Type'] == cell_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e89e66fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle \n",
    "with open(pickle_path + 'TILtcell_dfs_sub.pkl', 'wb') as f:\n",
    "    pickle.dump(TILtcell_dfs_sub, f)\n",
    "\n",
    "with open(pickle_path + 'LNtcell_dfs_sub.pkl', 'wb') as f:\n",
    "    pickle.dump(LNtcell_dfs_sub, f)\n",
    "\n",
    "# f.close()\n",
    "\n",
    "# '''load dictionary containing dataframes of non-normalized glycogene dataframes of just T-cells'''\n",
    "# pickle_in = open(pickle_path + \"TILtcell_dfs_sub.pkl\",\"rb\")\n",
    "# TILtcell_dfs_sub = pickle.load(pickle_in)\n",
    "# pickle_in = open(pickle_path + \"LNtcell_dfs_sub.pkl\",\"rb\")\n",
    "# LNtcell_dfs_sub = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8eec9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting all dataframes from df dictionary\n",
    "CD8_NaiveLike_df= TILtcell_dfs_sub['CD8_NaiveLike_df']\n",
    "CD8_EffectorMemory_df = TILtcell_dfs_sub['CD8_EffectorMemory_df']\n",
    "Th1_df = TILtcell_dfs_sub['Th1_df']\n",
    "CD8_EarlyActiv_df = TILtcell_dfs_sub['CD8_EarlyActiv_df']\n",
    "Treg_df = TILtcell_dfs_sub['Treg_df']\n",
    "CD8_Tex_df = TILtcell_dfs_sub['CD8_Tex_df']\n",
    "CD4_NaiveLike_df = TILtcell_dfs_sub['CD4_NaiveLike_df']\n",
    "Tfh_df = TILtcell_dfs_sub['Tfh_df']\n",
    "CD8_Tpex_df = TILtcell_dfs_sub['CD8_Tpex_df']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4343a43",
   "metadata": {},
   "source": [
    "## 7B. Add glycoscores to each subtype df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "03deca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off for PHA-L high: 1426; Cut-off for PHA-L low: 519\n",
      "Cut-off for PHA-L high: 2011; Cut-off for PHA-L low: 579\n",
      "Cut-off for PHA-L high: 416; Cut-off for PHA-L low: 187\n",
      "Cut-off for PHA-L high: 330; Cut-off for PHA-L low: 121\n",
      "Cut-off for PHA-L high: 506; Cut-off for PHA-L low: 233\n",
      "Cut-off for PHA-L high: 349; Cut-off for PHA-L low: 150\n",
      "Cut-off for PHA-L high: 403; Cut-off for PHA-L low: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off for PHA-L high: 253; Cut-off for PHA-L low: 126\n",
      "Cut-off for PHA-L high: 1240; Cut-off for PHA-L low: 465\n",
      "Cut-off for PHA-L high: 1691; Cut-off for PHA-L low: 624\n",
      "Cut-off for PHA-L high: 648; Cut-off for PHA-L low: 231\n",
      "Cut-off for PHA-L high: 400; Cut-off for PHA-L low: 133\n",
      "Cut-off for PHA-L high: 873; Cut-off for PHA-L low: 297\n",
      "Cut-off for PHA-L high: 937; Cut-off for PHA-L low: 343\n",
      "Cut-off for PHA-L high: 325; Cut-off for PHA-L low: 162\n",
      "Cut-off for PHA-L high: 182; Cut-off for PHA-L low: 105\n",
      "Cut-off for PHA-L high: 500; Cut-off for PHA-L low: 215\n",
      "Cut-off for PHA-L high: 379; Cut-off for PHA-L low: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n",
      "/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_2538/515535515.py:25: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
      "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
      "  cutoff = np.quantile(data_all.loc[:,ref_col_loc], [quantile_high, quantile_low], interpolation=\"nearest\").tolist()\n"
     ]
    }
   ],
   "source": [
    "TILglyconorm_sub_df = {}\n",
    "LNglyconorm_sub_df = {}\n",
    "\n",
    "# Make separate dataframe containing data for each t-cell subtype\n",
    "for name in df_names:\n",
    "    TILscored = glycoscore(TILtcell_dfs_sub[name])\n",
    "    TILglyconorm_sub_df[name] = TILscored\n",
    "    LNscored = glycoscore(LNtcell_dfs_sub[name])\n",
    "    LNglyconorm_sub_df[name] = LNscored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "49e93081",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save pickle of dictionary containing dataframe for each t-cell subtype normalized and scored\n",
    "- with genes in cols, cells in rows\n",
    "'''\n",
    "with open(pickle_path + 'TILglyconorm_sub_df.pkl', 'wb') as f:\n",
    "    pickle.dump(TILglyconorm_sub_df, f)\n",
    "\n",
    "with open(pickle_path + 'LNglyconorm_sub_df.pkl', 'wb') as f:\n",
    "    pickle.dump(LNglyconorm_sub_df, f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# '''load dictionary containing dataframes of non-normalized glycogene dataframes of just T-cells'''\n",
    "# pickle_in = open(pickle_path + \"TILglyconorm_sub_df.pkl\",\"rb\")\n",
    "# TILglyconorm_sub_df = pickle.load(pickle_in)\n",
    "# pickle_in = open(pickle_path + \"LNglyconorm_sub_df.pkl\",\"rb\")\n",
    "# LNglyconorm_sub_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e82008",
   "metadata": {},
   "source": [
    "### ASIDE: Make a concatenated dataframe that combines LN and TIL t-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e2d7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run once!!\n",
    "glycoTIL = glycosorted_TIL.copy()\n",
    "glycoLN = glycosorted_LN.copy()\n",
    "\n",
    "#Add info about where t-cells are from (LN or TIL) just in case as column\n",
    "glycoTIL['Location'] = ['TIL' for i in range(len(glycoTIL))]\n",
    "glycoLN['Location'] = ['LN' for i in range(len(glycoLN))]\n",
    "\n",
    "#add location info to barcode identifier\n",
    "glycoTIL.index = [f\"{x}_TIL\" for x in glycoTIL.index]\n",
    "glycoLN.index = [f\"{x}_LN\" for x in glycoLN.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "30f97689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dimensions of TIL: (9824, 265)\n",
      "Initial dimensions of LN: (10595, 265)\n",
      "Combined dimensions: (20419, 265)\n"
     ]
    }
   ],
   "source": [
    "combo_raw = pd.concat([glycoTIL, glycoLN])\n",
    "print('Initial dimensions of TIL:', glycoTIL.shape)\n",
    "print('Initial dimensions of LN:', glycoLN.shape)\n",
    "print('Combined dimensions:', combo_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649e0818",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combo_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t_/h82q6gld28zc219dv9bkpl2r0000gq/T/ipykernel_27260/2675684960.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombo_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'combo_raw' is not defined"
     ]
    }
   ],
   "source": [
    "combo_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9cd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save pickle \n",
    "# with open(pickle_path + 'combo_raw.pkl', 'wb') as f:\n",
    "#     pickle.dump(combo_raw, f)\n",
    "\n",
    "\n",
    "# f.close()\n",
    "\n",
    "# open via: \n",
    "#load updated df from pickle\n",
    "pickle_in = open(pickle_path +\"combo_raw.pkl\",\"rb\")\n",
    "combo_raw = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae460e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ahsa1</th>\n",
       "      <th>Api5</th>\n",
       "      <th>Atp6v1e1</th>\n",
       "      <th>Bcap31</th>\n",
       "      <th>Cops6</th>\n",
       "      <th>Csnk2b</th>\n",
       "      <th>Eif3i</th>\n",
       "      <th>Eif4g2</th>\n",
       "      <th>Gdi2</th>\n",
       "      <th>Hnrnpf</th>\n",
       "      <th>...</th>\n",
       "      <th>Galnt13</th>\n",
       "      <th>Galnt15</th>\n",
       "      <th>Galnt14</th>\n",
       "      <th>Dse</th>\n",
       "      <th>Dsel</th>\n",
       "      <th>Glce</th>\n",
       "      <th>Type</th>\n",
       "      <th>Biotin norm.</th>\n",
       "      <th>PHA-L</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AATCCAGCATATGCTG-1_TIL</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>13596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCCTCTATCTGGTTCC-1_TIL</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>4131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GACGTTACACGCCAGT-1_TIL</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>2879</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGACAGACAGCTGTAT-1_TIL</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>1781</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGACTTTTCACATAGC-1_TIL</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>1234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATTGGACGTAAACACA-1_LN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGGACGTAGTGGAGTC-1_LN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTACATTCATTTCAGG-1_LN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGCGTCCAGTCAGCC-1_LN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGACTAGCACCTTGTC-1_LN</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tfh</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Ahsa1 Api5 Atp6v1e1 Bcap31 Cops6 Csnk2b Eif3i Eif4g2  \\\n",
       "AATCCAGCATATGCTG-1_TIL     2    0        0      0     0      2     3      1   \n",
       "GCCTCTATCTGGTTCC-1_TIL     2    1        0     12     0      1     2      7   \n",
       "GACGTTACACGCCAGT-1_TIL     4    2        1     12     9      6    16      8   \n",
       "GGACAGACAGCTGTAT-1_TIL     0    0        0     12     0      0     0      1   \n",
       "TGACTTTTCACATAGC-1_TIL     8    3        5      7     3      3     2     23   \n",
       "...                      ...  ...      ...    ...   ...    ...   ...    ...   \n",
       "ATTGGACGTAAACACA-1_LN      0    0        0      0     0      0     1      1   \n",
       "CGGACGTAGTGGAGTC-1_LN      1    1        0      1     2      2     2      4   \n",
       "CTACATTCATTTCAGG-1_LN      0    1        0      0     2      0     0      4   \n",
       "TTGCGTCCAGTCAGCC-1_LN      0    1        0      0     0      1     2      1   \n",
       "TGACTAGCACCTTGTC-1_LN      0    1        0      0     0      0     0      1   \n",
       "\n",
       "                       Gdi2 Hnrnpf  ... Galnt13 Galnt15 Galnt14 Dse Dsel Glce  \\\n",
       "AATCCAGCATATGCTG-1_TIL    2      5  ...       0       0       0   0    0    0   \n",
       "GCCTCTATCTGGTTCC-1_TIL    1      8  ...       0       0       0   2    0    0   \n",
       "GACGTTACACGCCAGT-1_TIL    3      3  ...       0       0       0   1    0    0   \n",
       "GGACAGACAGCTGTAT-1_TIL    1      4  ...       0       0       0   1    0    0   \n",
       "TGACTTTTCACATAGC-1_TIL    5     27  ...       0       0       0   1    1    1   \n",
       "...                     ...    ...  ...     ...     ...     ...  ..  ...  ...   \n",
       "ATTGGACGTAAACACA-1_LN     1      1  ...       0       0       0   0    0    0   \n",
       "CGGACGTAGTGGAGTC-1_LN     3      2  ...       0       0       0   0    0    0   \n",
       "CTACATTCATTTCAGG-1_LN     1      4  ...       0       0       0   0    0    0   \n",
       "TTGCGTCCAGTCAGCC-1_LN     1      5  ...       0       0       0   0    0    0   \n",
       "TGACTAGCACCTTGTC-1_LN     0      1  ...       0       0       0   0    0    0   \n",
       "\n",
       "                       Type Biotin norm. PHA-L Location  \n",
       "AATCCAGCATATGCTG-1_TIL  Tfh        13596   1.0      TIL  \n",
       "GCCTCTATCTGGTTCC-1_TIL  Tfh         4131   1.0      TIL  \n",
       "GACGTTACACGCCAGT-1_TIL  Tfh         2879   1.0      TIL  \n",
       "GGACAGACAGCTGTAT-1_TIL  Tfh         1781   1.0      TIL  \n",
       "TGACTTTTCACATAGC-1_TIL  Tfh         1234   1.0      TIL  \n",
       "...                     ...          ...   ...      ...  \n",
       "ATTGGACGTAAACACA-1_LN   Tfh          119   0.0       LN  \n",
       "CGGACGTAGTGGAGTC-1_LN   Tfh          112   0.0       LN  \n",
       "CTACATTCATTTCAGG-1_LN   Tfh          102   0.0       LN  \n",
       "TTGCGTCCAGTCAGCC-1_LN   Tfh           76   0.0       LN  \n",
       "TGACTAGCACCTTGTC-1_LN   Tfh           71   0.0       LN  \n",
       "\n",
       "[109 rows x 265 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_raw[combo_raw['Type'] == 'Tfh']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59abf2c",
   "metadata": {},
   "source": [
    "### SPlit by subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ae1e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now want to split up glycosorted dataframe into sub-dataframes for\n",
    "each of the different T-cell subtypes. TO do this, this code block takes in the glycosorted\n",
    "dataframe data as the input and spits out a dictionaryt containing:\n",
    "- t-cell type as key \n",
    "- matrix containing raw expression data for dataframe as values\n",
    "\n",
    "'''\n",
    "# Get list of T-cell subtypes for which to make a dataframe for TILs\n",
    "tcell_subtypes = glycosorted_TIL['Type'].unique()\n",
    "\n",
    "#make dataframe names for later access\n",
    "df_names = [i+'_df' for i in list(tcell_subtypes)]\n",
    "\n",
    "# Make copy of original df just in case\n",
    "split_df = glycosorted_TIL.copy()\n",
    "\n",
    "TILtcell_dfs = {}\n",
    "\n",
    "# Make separate dataframe containing data for each t-cell subtype\n",
    "for cell_type, name in zip(tcell_subtypes, df_names):\n",
    "    TILtcell_dfs[name] = split_df[split_df['Type'] == cell_type]\n",
    "    \n",
    "###----------------------------------------------------------------------\n",
    "# Get list of T-cell subtypes for which to make a dataframe for LNs\n",
    "tcell_subtypes = glycosorted_LN['Type'].unique()\n",
    "\n",
    "#make dataframe names for later access\n",
    "df_names = [i+'_df' for i in list(tcell_subtypes)]\n",
    "\n",
    "\n",
    "# Make copy of original df just in case\n",
    "split_df = glycosorted_LN.copy()\n",
    "\n",
    "LNtcell_dfs = {}\n",
    "# Make separate dataframe containing data for each t-cell subtype\n",
    "for cell_type, name in zip(tcell_subtypes, df_names):\n",
    "    LNtcell_dfs[name] = split_df[split_df['Type'] == cell_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cb3e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle \n",
    "with open(pickle_path + 'TILtcell_dfs.pkl', 'wb') as f:\n",
    "    pickle.dump(TILtcell_dfs, f)\n",
    "    \n",
    "with open(pickle_path + 'LNtcell_dfs.pkl', 'wb') as f:\n",
    "    pickle.dump(LNtcell_dfs, f)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# open via: \n",
    "# #load updated df from pickle\n",
    "# pickle_in = open(pickle_path + \"TILtcell_dfs.pkl\",\"rb\")\n",
    "# TILtcell_dfs = pickle.load(pickle_in)\n",
    "\n",
    "# pickle_in = open(pickle_path + \"LNtcell_dfs.pkl\",\"rb\")\n",
    "# LNtcell_dfs = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741688f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
